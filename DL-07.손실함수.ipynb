{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL-07.손실함수.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNOpgXJfNVm0T6pk8oClxDV"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XAn1X8e9nNi1"},"source":["# 머신러닝\n","- 알고리즘 짜기 어렵기 때문에 데이터를 대신 활용\n","- 사람이 특징 추출 직접 설계\n","- 기계가 직접 패턴 학습\n","- 문제에 적합한 특징을 사용하지 않는 경우, 특징 설계를 하지 않은 경우 -> 좋은 결과물을 얻기 어렵다."]},{"cell_type":"markdown","metadata":{"id":"gLphcNwlnnlD"},"source":["# 딥러닝\n","- 머신러닝의 한 종류\n","- 사람이 특징 추출 설계할 필요 X\n","- 신경망이 알아서"]},{"cell_type":"markdown","metadata":{"id":"PZOJhJTTn9E2"},"source":["end-to-end machine learning : 종단간 기계학습\n","- 데이터에서 목표한 결과를 처음부터 끝까지 사람의 개입없이 얻어낼 수 있다."]},{"cell_type":"markdown","metadata":{"id":"0_xRfQGKkpAp"},"source":["# 신경망의 학습\n","- 훈련 데이터로부터 패턴을 찾아\n","- 가중치 매개변수(가중치-w, 편향-b)의 최적값을 자동으로 획득하는 것\n","- 사람이 직접 매개변수 설정하지 X\n","- 학습지표 : 손실함수(loss function, cost function)\n","- 학습의 목적 : 손실함수값을 가장 작게 만드는 가중치 매개변수를 찾는 것"]},{"cell_type":"markdown","metadata":{"id":"zi9LjVEkk-84"},"source":["수많은 데이터셋을 위해 사람이 직접 가중치 설정하는 것 불가능.\n","\n","신경망의 학습을 통해 가중치 매개변수 자동 설정됨."]},{"cell_type":"markdown","metadata":{"id":"QoRKeWdQlUad"},"source":["머신러닝에서는 사람의 개입을 최소화, 수집한 데이터를 토대로 패턴을 찾으려 시도.\n","\n","hyper parameter를 사람이 입력 X"]},{"cell_type":"markdown","metadata":{"id":"iH3wWQEGmZDT"},"source":["단, 이미지를 벡터화하는 경우도 많은 데 벡터로 변환할 때 사용하는 특징 추출은 사람이 직접 설계해야한다.\n","\n","문제에 적합한 특징 사용 X 또는 특징 설계 X -> 좋은 결과물을 얻기 어렵다.\n","\n","ex) 개, 고양이의 얼굴 구분"]},{"cell_type":"markdown","metadata":{"id":"ene6YCNnoGND"},"source":["## 신경망 학습지표 : 손실함수(loss function)\n","- 신경망 성능의 **나쁨**을 나타내는 지표\n","- MSE(평균제곱오차)\n","- cross entropy(교차 엔트로피 오차)"]},{"cell_type":"markdown","metadata":{"id":"Gq9tO3RTogKu"},"source":["### MSE\n","- $\\begin{align}\n","E = \\frac{1}{2}\\sum_{k}(y_k-t_k)^2\n","\\end{align}$\n","  - $y_k$ : 신경망의 예측값\n","  - $t_k$ : 정답 label. target.\n","  - $k$ : 데이터의 차원 수"]},{"cell_type":"code","metadata":{"id":"uYBz4KSLpLNF"},"source":["# 예시\n","import numpy as np\n","y1 = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])\n","# 신경망의 softmax 함수의 출력물\n","# 예측값\n","# 2번 클래스가 될 확률이 제일 크다.\n","\n","t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n","# 정답\n","# 2번 클래스"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZebFlByIpVLw"},"source":["# MSE 식을 구현해보자.\n","def mean_squared_error(y, t):\n","  return 0.5 * np.sum((y - t) ** 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mwcdHY6aqA8D","executionInfo":{"status":"ok","timestamp":1604569384897,"user_tz":-540,"elapsed":739,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"fecf6557-46b8-488c-d278-58dceb1a1017","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 위의 y1이 정답이 2번 클래스인데\n","# 예측도 2번 클래스로 했으니까\n","# 맞게 예측했을 때의 MSE 값을 구해보자.\n","mse1 = mean_squared_error(y1, t)\n","print(mse1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.09750000000000003\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M5fWkkXPqSr3","executionInfo":{"status":"ok","timestamp":1604569384898,"user_tz":-540,"elapsed":734,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"1db62282-9f47-4f9a-a806-dc3bd944760a","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 손실함수값이 매우 낮다는 걸 알 수 있다.\n","\n","# 그러면 임의로 잘못 예측했을 때의 MSE 값은 어떻게 나오는지 해보자.\n","\n","y2 = np.array([0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0])\n","# 7번 클래스로 잘못 예측했다.\n","\n","mse2 = mean_squared_error(y2, t)\n","print(mse2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.5975\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BdGeTRmArkzQ"},"source":["# 정답을 맞게 예측했을 때의 MSE 값보다 훨씬 큰 것을 알 수 있다."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qQ89UcO0rxXY"},"source":["### CEE(Cross Entropy Error) - 교차 엔트로피 오차\n","- $\\begin{align}\n","E = -\\sum_{k}t_klog\\;y_k\n","\\end{align}$\n","- 여기서의 $log$는 $log_e$\n","- $y_k$ : 신경망의 출력(예측값)\n","- $t_k$ : 정답 label(One-hot Encoding 된 형태). target\n","\n","\n","- $t_k$가 원핫인코딩되있는 형태이기 때문에 1일때. 즉, 정답을 맞춘 경우들만 계산을 하는 형태이다.\n","- 즉, 정답일 때의 출력이 전체 값을 정하게 된다.\n","\n","\n","- MSE 값보다 결과를 더 극대화시킨다."]},{"cell_type":"code","metadata":{"id":"_AQXndi2tHdz"},"source":["# CEE(교차 엔트로피 오차)를 구현해보자.\n","def cross_entropy_error(y, t):\n","  delta = 1e-7\n","  return -np.sum(t * np.log(y + delta))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kybN0OENtSIz"},"source":["# 아주 작은 값인 delta를 더하는 이유?\n","# log(0) = -np.inf 이다.\n","# 따라서, 더이상 계산할 수 없기 때문에 아주 작은 값을 더해, 절대 0이 되지 않도록 막아주는 역할을 한다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xiPUm6Lt0WE","executionInfo":{"status":"ok","timestamp":1604569384901,"user_tz":-540,"elapsed":720,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"cfed302e-1630-46bb-eaf9-d5eb868ac34c","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 아까의 y1, y2, t를 이번에는 CEE(교차 엔트로피 오차)를 이용해서 구해보자.\n","# 단, t가 One-hot encoding 된 상태인지 우선 확인하자.\n","# CEE(교차 엔트로피 오차)는 t값으로 One-hot Encoding된 값을 사용한다.\n","print(t)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0 0 1 0 0 0 0 0 0 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zRTknSNFyYzI"},"source":["# One-hot Encoding이 되어있는 상태가 맞다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBP2PSvfyWaD","executionInfo":{"status":"ok","timestamp":1604569384902,"user_tz":-540,"elapsed":714,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"68c3d2dc-7247-4fa8-aa5d-53259be4a0f1","colab":{"base_uri":"https://localhost:8080/"}},"source":["cee1 = cross_entropy_error(y1, t)  # 정답을 맞췄을 때\n","cee2 = cross_entropy_error(y2, t)  # 정답을 맞추지 못했을 때\n","print(cee1, cee2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.510825457099338 2.302584092994546\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q_sZ9T8WuOMN","executionInfo":{"status":"ok","timestamp":1604569385460,"user_tz":-540,"elapsed":1266,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"dadbf893-1c0c-4ab2-e025-df3b594538c1","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 정답을 맞췄을 때보다 맞추지 못했을 때의 CEE 값. 교차 엔트로피 오차값이 훨씬 큰 것을 알 수 있다.\n","# 아까 MSE 값과 지금의 CEE 값의 차이가 있는 지 봐보자.\n","print(mse1, cee1)\n","print(mse2, cee2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.09750000000000003 0.510825457099338\n","0.5975 2.302584092994546\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9FSXVPYAuaHn","executionInfo":{"status":"ok","timestamp":1604569385461,"user_tz":-540,"elapsed":1261,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"91797b75-a501-4dbf-e935-48a69b8ecdbb","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 정답을 맞췄을 때와, 맞추지 못했을 때\n","# 두 경우 모두\n","# MSE < CEE 를 만족한다.\n","\n","print(cee1/mse1)\n","print(cee2/mse2)\n","\n","# 정답을 맞췄을 때보다 맞추지 못했을 때 CEE 값이 훨씬 더 커진다.\n","# MSE 값보다 CEE 값이 더 결과를 극대화시킨다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["5.239235457429106\n","3.853697226769114\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kmP3FJ1Nuszw"},"source":["## 미니배치 학습\n","- 위의 CEE 공식은 모든 데이터에 대한 손실함수를 적용시킨 것\n","- 만약에 배치 학습을 시키게 된다면\n","- 데이터가 batch_size 만큼씩 묶음으로 된다.\n","- 그 묶음마다 손실함수를 구하고, 총 손실함수들의 평균을 구하게 되면 **평균 손실 함수**가 된다.\n","- $\\begin{align}\n","E = -\\frac{1}{N}\\sum_n\\;\\sum_{k}t_{nk}log\\;y_{nk}\n","\\end{align}$\n","  - $N$ : 데이터의 갯수\n","  - $y_nk$ : 신경망의 출력\n","  - $t_nk$ : 정답 label"]},{"cell_type":"markdown","metadata":{"id":"qCfzCBzbvVEn"},"source":["빅데이터의 모든 데이터의 손실함수를 계산하는 것은 힘들다.\n","\n","따라서, 데이터의 일부만을 뽑은 후, 손실함수를 계산해 원래 손실함수의 근사치로 활용한다.\n","\n","미니배치 : 그 뽑힌 일부의 데이터"]},{"cell_type":"markdown","metadata":{"id":"2liP98MYNrB0"},"source":["배치 : 컴퓨터의 데이터 처리 형태의 하나. 처리해야 할 데이터를 일정기간동안 일정량 정리하여 처리하는 것\n","\n","일 단위, 월 단위마다 모아두고 그것을 **하나로 종합**하여 처리하는 것을 배치 처리 또는 일괄처리라고 한다.\n","\n","미니배치처리 : 인공지능이 학습을 할 때 거대한 양의 데이터를 한꺼번에 학습하지 않고 단위별로 쪼개서 하는 것\n"]},{"cell_type":"code","metadata":{"id":"3k6Rdm-pxEfh"},"source":["# 아까는 tensorflow.keras.datasets에 담겨있는 mnist 를 불러오는 식으로 MNIST 신경망을 만들었었다.\n","\n","# 이번에는 mnist.py 파일을 이용해서 로드해보자."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWHY-ZdzxWzM","executionInfo":{"status":"ok","timestamp":1604569748657,"user_tz":-540,"elapsed":735,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"1b8f5cbc-3896-42c7-879a-425f3bd2dcd6","colab":{"base_uri":"https://localhost:8080/"}},"source":["import sys\n","sys.path"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['',\n"," '/env/python',\n"," '/usr/lib/python36.zip',\n"," '/usr/lib/python3.6',\n"," '/usr/lib/python3.6/lib-dynload',\n"," '/usr/local/lib/python3.6/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n"," '/root/.ipython',\n"," '..',\n"," '..',\n"," '..',\n"," '..',\n"," '..',\n"," '..']"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"ouQKiMj-x4hE"},"source":["sys.path.append(\"C:\\\\Users\\\\geunho\\\\Downloads\")\n","# 컴퓨터의 Downloads 폴더를 sys.path에 추가"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tszPMKdzNf_","executionInfo":{"status":"ok","timestamp":1604572910181,"user_tz":-540,"elapsed":587,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"b3aa4262-bc74-4dee-a0e6-164e6aa7e3e3","colab":{"base_uri":"https://localhost:8080/"}},"source":["sys.path  # 내가 지정한 path가 시스템의 path에 추가되었는 지 확인"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['',\n"," '/env/python',\n"," '/usr/lib/python36.zip',\n"," '/usr/lib/python3.6',\n"," '/usr/lib/python3.6/lib-dynload',\n"," '/usr/local/lib/python3.6/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n"," '/root/.ipython',\n"," '..',\n"," '..',\n"," '..',\n"," '..',\n"," '..',\n"," '..',\n"," 'C:\\\\Users\\\\geunho\\\\Downloads']"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"-07GpenNzSog"},"source":["import mnist  # mnist.py 파일 import"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bkzRTzqW_teb","executionInfo":{"status":"ok","timestamp":1604572919810,"user_tz":-540,"elapsed":638,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"dfc92ca4-5304-417d-97e6-16b94a8357a7","colab":{"base_uri":"https://localhost:8080/"}},"source":["dir(mnist)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['__builtins__',\n"," '__cached__',\n"," '__doc__',\n"," '__file__',\n"," '__loader__',\n"," '__name__',\n"," '__package__',\n"," '__spec__',\n"," '_change_one_hot_label',\n"," '_convert_numpy',\n"," '_download',\n"," '_load_img',\n"," '_load_label',\n"," 'dataset_dir',\n"," 'download_mnist',\n"," 'gzip',\n"," 'img_dim',\n"," 'img_size',\n"," 'init_mnist',\n"," 'key_file',\n"," 'load_mnist',\n"," 'np',\n"," 'os',\n"," 'pickle',\n"," 'save_file',\n"," 'test_num',\n"," 'train_num',\n"," 'url_base',\n"," 'urllib']"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"zxhnnk87_04i"},"source":["(X_train, y_train), (X_test, y_test) = mnist.load_mnist(normalize=True, flatten=True, one_hot_label=True)\n","# 인수\n","# normalize : 입력 이미지의 픽셀 값을 0~1 사이의 값으로 정규화할지?\n","# 원래는 픽셀값 0 ~ 255라서 정규화 필요\n","# flatten : 입력 이미지를 평탄화해서 1차원 배열로 만들지?\n","# 28*28이미지를 가로로 쭉 펴준다.\n","# one_hot_label : label을 One-hot Encoding한 상태로 저장할지?\n","# 정답 위치의 원소만 1, 나머지는 0인 배열"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_lvSbL6AIl1","executionInfo":{"status":"ok","timestamp":1604574359025,"user_tz":-540,"elapsed":636,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"fd490592-a080-42be-8f86-e96ade3a680c","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"WG_1Qm23AOtZ","executionInfo":{"status":"ok","timestamp":1604574278595,"user_tz":-540,"elapsed":737,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"8910bd46-adbd-44b3-e3ee-0255a604c2d6","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(60000, 784) (60000, 10) (10000, 784) (10000, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-oMLEvlDATYS"},"source":["# 데이터가 잘 불러와진 것 확인"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3koQ_eTBhB6","executionInfo":{"status":"ok","timestamp":1604574280722,"user_tz":-540,"elapsed":615,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"f818acb5-d741-4910-8d8e-a87d5116db37","colab":{"base_uri":"https://localhost:8080/"}},"source":["y_test\n","# one_hot_label=True 라고 써서\n","# one-hot encoding 된 결과로 출력된다."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 1., 0., 0.],\n","       [0., 0., 1., ..., 0., 0., 0.],\n","       [0., 1., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"U1mjyyw_BjIM","executionInfo":{"status":"ok","timestamp":1604574325555,"user_tz":-540,"elapsed":599,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"8a611d74-a3af-4754-fafe-7f0e2dfd0fc5","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_train[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n","       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n","       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n","       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n","       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n","       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n","       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n","       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n","       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n","       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n","       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n","       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.05490196,\n","       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.54509807,\n","       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n","       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n","       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n","       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n","       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n","       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n","       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n","       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.15294118,\n","       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n","       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n","       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n","       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n","       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n","       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n","       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n","       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n","       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n","       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        ], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":77}]},{"cell_type":"code","metadata":{"id":"M0zGIPfOB-ex"},"source":["# 미니배치 학습은 전체 데이터 중에서 일부를 추려서 원본 데이터의 근사치로 사용하는 것이니까\n","# 일부만 떼내도록 하자."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JrlXWMinGCJK"},"source":["# 미니배치 사이즈를 10으로 해서 빼오자.\n","train_size = X_train.shape[0]  # 훈련 데이터 이미지 갯수\n","batch_size = 10  # 미니배치 사이즈. 미니배치 학습에 사용되는 데이터의 갯수.\n","# 학습 데이터 60000개 중에서 10개만 사용하겠다.\n","\n","batch_mask = np.random.choice(train_size, batch_size)\n","# np.random.choice(a, size, replace=True, p=None)\n","# a : 1차원 배열\n","# size : 갯수\n","# replace : 복원추출할지?\n","# p : 각각원소가 뽑힐 확률 지정?\n","\n","# 전체 훈련 데이터 중에서 지정한 batch_size. 즉, 10개만 랜덤으로 숫자를 뽑아준다.\n","\n","X_batch = X_train[batch_mask]\n","y_batch = y_train[batch_mask]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"17ysqEP6HMcu","executionInfo":{"status":"ok","timestamp":1604574950746,"user_tz":-540,"elapsed":557,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"fc26adac-9932-481c-f38e-9c6120840139","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 전체 데이터 60000개의 이미지 중에서 랜덤으로 숫자를 10개 뽑아서\n","# 그 index에 해당하는 미니배치를 뽑았다.\n","print(X_batch)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"luvUFSAtHrLo"},"source":["# 이제, 미니배치 학습을 하였을 때\n","# 손실함수값은 어떻게 되는지 알아보자."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QcvX5tT5H0Pb"},"source":["### 배치용 교차 엔트로피 구현"]},{"cell_type":"code","metadata":{"id":"zpz91x2gH2Nc"},"source":["def cross_entropy_error_v1(y, t):\n","  if y.ndim == 1:\n","    # 예측값의 차원이 1차원\n","    # One-hot Encoding되지 않은 형태\n","    # 데이터 하나당 교차 엔트로피 오차를 구하는 경우\n","    \n","    \n"],"execution_count":null,"outputs":[]}]}