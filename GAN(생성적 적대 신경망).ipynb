{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN(생성적 적대 신경망).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMJgotvs4kpuzbsOPmnsavu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gYgvqbGvFvzM"},"source":["참고 : Generative Deep Learning 미술관에 GAN 딥러닝 실전 프로젝트 - 데이비드 포스터 지음 (출판사 : 한빛미디어)\r\n","\r\n","참고 : https://sunghan-kim.github.io/ml/3min-dl-ch09/"]},{"cell_type":"markdown","metadata":{"id":"rbEECPhMBcLE"},"source":["# GAN(Generative Adversarial Network) : 생성적 적대 신경망\r\n","- 생성자(generator), 판별자(discriminator) 네트워크 2개가 경쟁하는 것\r\n","- 생성자 : 원본 데이터셋에서 샘플링한 것처럼 보이는 샘플로 변환 (진짜같은 가짜 생성)\r\n","- 판별자 : 원본 데이터셋에서 추출한 샘플인지 생성자가 만든 가짜인지를 구별 (진짜인지, 가짜인지 구별)\r\n","- <img src=\"https://1.bp.blogspot.com/-n9mKBe3m9zw/WZkBAS_oUcI/AAAAAAAAAIU/WKIHqZp7z_IvQ-arRsEvWDp8C8foPDc2wCLcBGAs/s1600/6.png\" width=600>\r\n","- 생성자는 더 진짜같은 가짜를 만들어내고, 판별자는 정확하게 진짜와 가짜를 구별하는 능력을 유지하도록 학습한다."]},{"cell_type":"code","metadata":{"id":"gfqQPt--UL6G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873948732,"user_tz":-540,"elapsed":6463,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"6384fdc8-6569-4761-b0c0-354a79e65139"},"source":["# 구글 드라이브 import\r\n","from google.colab import drive\r\n","drive.mount(\"/content/drive\")\r\n","\r\n","# 기본 환경 설정\r\n","!git clone https://github.com/rickiepark/GDL_code.git\r\n","!git pull\r\n","!conda create -n generative python=3.6 ipykernel\r\n","!pip install virtualenv virtualenvwrapper\r\n","!mkvirtualenv generative\r\n","!pip install absl-py appnope backcall bleach cloudpickle cycler dask decorator defusedxml entrypoints gast grpcio h5py ipykernel ipython ipython-genutils ipywidgets jedi Jinja2 jsonschema jupyter jupyter-client jupyter-console jupyter-core Keras Keras-Applications Keras-Preprocessing kiwisolver Markdown MarkupSafe matplotlib mistune music21 nbconvert nbformat networkx notebook numpy pandas pandocfilters parso pexpect pickleshare Pillow prometheus-client prompt-toolkit protobuf ptyprocess pydot Pygments pyparsing python-dateutil pytz PyWavelets PyYAML pyzmq qtconsole scikit-image scipy Send2Trash six tensorboard tensorflow termcolor terminado testpath toolz tornado traitlets wcwidth webencodings Werkzeug widgetsnbextension"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","fatal: destination path 'GDL_code' already exists and is not an empty directory.\n","fatal: not a git repository (or any of the parent directories): .git\n","/bin/bash: conda: command not found\n","Requirement already satisfied: virtualenv in /usr/local/lib/python3.6/dist-packages (20.2.2)\n","Requirement already satisfied: virtualenvwrapper in /usr/local/lib/python3.6/dist-packages (4.8.4)\n","Requirement already satisfied: appdirs<2,>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from virtualenv) (1.4.4)\n","Requirement already satisfied: importlib-resources>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from virtualenv) (3.3.0)\n","Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv) (1.15.0)\n","Requirement already satisfied: filelock<4,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv) (3.0.12)\n","Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from virtualenv) (3.1.1)\n","Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from virtualenv) (0.3.1)\n","Requirement already satisfied: stevedore in /usr/local/lib/python3.6/dist-packages (from virtualenvwrapper) (3.3.0)\n","Requirement already satisfied: virtualenv-clone in /usr/local/lib/python3.6/dist-packages (from virtualenvwrapper) (0.5.4)\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources>=1.0; python_version < \"3.7\"->virtualenv) (3.4.0)\n","Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from stevedore->virtualenvwrapper) (5.5.1)\n","/bin/bash: mkvirtualenv: command not found\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (0.10.0)\n","Requirement already satisfied: appnope in /usr/local/lib/python3.6/dist-packages (0.1.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (0.2.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (3.2.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (1.3.0)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (0.10.0)\n","Requirement already satisfied: dask in /usr/local/lib/python3.6/dist-packages (2.12.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (4.4.2)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (0.6.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (0.3)\n","Requirement already satisfied: gast in /usr/local/lib/python3.6/dist-packages (0.3.3)\n","Requirement already satisfied: grpcio in /usr/local/lib/python3.6/dist-packages (1.34.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (4.10.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (5.5.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (0.2.0)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (7.5.1)\n","Requirement already satisfied: jedi in /usr/local/lib/python3.6/dist-packages (0.17.2)\n","Requirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (2.11.2)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (2.6.0)\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (5.3.5)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (5.2.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (4.7.0)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n","Requirement already satisfied: Keras-Applications in /usr/local/lib/python3.6/dist-packages (1.0.8)\n","Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.6/dist-packages (1.1.2)\n","Requirement already satisfied: kiwisolver in /usr/local/lib/python3.6/dist-packages (1.3.1)\n","Requirement already satisfied: Markdown in /usr/local/lib/python3.6/dist-packages (3.3.3)\n","Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (1.1.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n","Requirement already satisfied: mistune in /usr/local/lib/python3.6/dist-packages (0.8.4)\n","Requirement already satisfied: music21 in /usr/local/lib/python3.6/dist-packages (5.5.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (5.6.1)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (5.0.8)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (2.5)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (5.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n","Requirement already satisfied: pandocfilters in /usr/local/lib/python3.6/dist-packages (1.4.3)\n","Requirement already satisfied: parso in /usr/local/lib/python3.6/dist-packages (0.7.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.6/dist-packages (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (0.7.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (0.9.0)\n","Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.6/dist-packages (1.0.18)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (3.12.4)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.6/dist-packages (0.6.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n","Requirement already satisfied: Pygments in /usr/local/lib/python3.6/dist-packages (2.6.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (2.4.7)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (2.8.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (2018.9)\n","Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (1.1.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (3.13)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (20.0.0)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (5.0.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (1.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.15.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: terminado in /usr/local/lib/python3.6/dist-packages (0.9.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (0.4.4)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (0.11.1)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (5.1.1)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (4.3.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (0.2.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Requirement already satisfied: Werkzeug in /usr/local/lib/python3.6/dist-packages (1.0.1)\n","Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.6/dist-packages (3.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach) (20.7)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython) (50.3.2)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython) (0.8.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from Markdown) (3.1.1)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole) (1.9.0)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.17.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.4.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.7.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (2.23.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.36.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->Markdown) (3.4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9PshFuxfFJKr"},"source":["# 애니멀간 데이터\r\n","- 28x28 픽셀, 흑백 낙서 이미지 데이터\r\n","- 주제별로 labeling 되어있음"]},{"cell_type":"markdown","metadata":{"id":"CoH1CZ_SVF0A"},"source":["# GAN 모델링"]},{"cell_type":"code","metadata":{"id":"t_EzsWACW_gx","executionInfo":{"status":"ok","timestamp":1607873949348,"user_tz":-540,"elapsed":7073,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}}},"source":["# GAN class 정의\r\n","\r\n","from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\r\n","# from keras.layers.merge import _Merge\r\n","# keras 2.x 버전에서는 작동 안 함\r\n","# 대신에 Add나 concatenate 사용\r\n","from keras.layers import Add, Concatenate\r\n","\r\n","from keras.models import Model, Sequential\r\n","from keras import backend as K\r\n","from keras.optimizers import Adam, RMSprop\r\n","from keras.utils import plot_model\r\n","from keras.initializers import RandomNormal\r\n","\r\n","import numpy as np\r\n","import json\r\n","import os\r\n","import pickle as pkl\r\n","import matplotlib.pyplot as plt\r\n","\r\n","def concatenate(x1, x2):\r\n","  merged = Concatenate([x1, x2])\r\n","  return merged\r\n","\r\n","class GAN():\r\n","  # parameter 설정, model build, compile\r\n","    def __init__(self\r\n","        , input_dim\r\n","        , discriminator_conv_filters\r\n","        , discriminator_conv_kernel_size\r\n","        , discriminator_conv_strides\r\n","        , discriminator_batch_norm_momentum\r\n","        , discriminator_activation\r\n","        , discriminator_dropout_rate\r\n","        , discriminator_learning_rate\r\n","        , generator_initial_dense_layer_size\r\n","        , generator_upsample\r\n","        , generator_conv_filters\r\n","        , generator_conv_kernel_size\r\n","        , generator_conv_strides\r\n","        , generator_batch_norm_momentum\r\n","        , generator_activation\r\n","        , generator_dropout_rate\r\n","        , generator_learning_rate\r\n","        , optimiser\r\n","        , z_dim\r\n","        ):\r\n","\r\n","        self.name = 'gan'\r\n","\r\n","        # 파라미터 초기화\r\n","        self.input_dim = input_dim\r\n","        self.discriminator_conv_filters = discriminator_conv_filters\r\n","        self.discriminator_conv_kernel_size = discriminator_conv_kernel_size\r\n","        self.discriminator_conv_strides = discriminator_conv_strides\r\n","        self.discriminator_batch_norm_momentum = discriminator_batch_norm_momentum\r\n","        self.discriminator_activation = discriminator_activation\r\n","        self.discriminator_dropout_rate = discriminator_dropout_rate\r\n","        self.discriminator_learning_rate = discriminator_learning_rate\r\n","\r\n","        self.generator_initial_dense_layer_size = generator_initial_dense_layer_size\r\n","        self.generator_upsample = generator_upsample\r\n","        self.generator_conv_filters = generator_conv_filters\r\n","        self.generator_conv_kernel_size = generator_conv_kernel_size\r\n","        self.generator_conv_strides = generator_conv_strides\r\n","        self.generator_batch_norm_momentum = generator_batch_norm_momentum\r\n","        self.generator_activation = generator_activation\r\n","        self.generator_dropout_rate = generator_dropout_rate\r\n","        self.generator_learning_rate = generator_learning_rate\r\n","        \r\n","        self.optimiser = optimiser\r\n","        self.z_dim = z_dim\r\n","\r\n","        # discriminator, generator의 layer 갯수\r\n","        self.n_layers_discriminator = len(discriminator_conv_filters)\r\n","        self.n_layers_generator = len(generator_conv_filters)\r\n","\r\n","        # 정규분포로 초깃값 설정\r\n","        self.weight_init = RandomNormal(mean=0., stddev=0.02)\r\n","\r\n","        self.d_losses = []\r\n","        self.g_losses = []\r\n","\r\n","        self.epoch = 0\r\n","\r\n","        # discriminator, generator 모델 생성 메소드\r\n","        self._build_discriminator()\r\n","        self._build_generator()\r\n","\r\n","        self._build_adversarial()\r\n","\r\n","    # 활성화 함수 지정\r\n","    def get_activation(self, activation):\r\n","        if activation == 'leaky_relu':\r\n","            layer = LeakyReLU(alpha = 0.2)\r\n","        else:\r\n","            layer = Activation(activation)\r\n","        return layer\r\n","\r\n","    # discriminator(판별자) 생성\r\n","    # Conv2D, BatchNormalization, activation, Dropout, Flatten, Dense, Model\r\n","    # ------------------------------------------------------------------------\r\n","    # input : image\r\n","    # output : 진짜 이미지일 확률. 0~1 사이의 값.\r\n","    # ------------------------------------------------------------------------\r\n","    def _build_discriminator(self):\r\n","\r\n","        ### THE discriminator\r\n","        discriminator_input = Input(shape=self.input_dim, name='discriminator_input')  # discriminator의 input 정의\r\n","\r\n","        x = discriminator_input\r\n","\r\n","        # 합성곱 층(convolution layer) 쌓기\r\n","        for i in range(self.n_layers_discriminator):\r\n","\r\n","            x = Conv2D(\r\n","                filters = self.discriminator_conv_filters[i]\r\n","                , kernel_size = self.discriminator_conv_kernel_size[i]\r\n","                , strides = self.discriminator_conv_strides[i]\r\n","                , padding = 'same'\r\n","                , name = 'discriminator_conv_' + str(i)\r\n","                , kernel_initializer = self.weight_init\r\n","                )(x)\r\n","\r\n","            if self.discriminator_batch_norm_momentum and i > 0:\r\n","                x = BatchNormalization(momentum = self.discriminator_batch_norm_momentum)(x)\r\n","\r\n","            x = self.get_activation(self.discriminator_activation)(x)\r\n","\r\n","            if self.discriminator_dropout_rate:\r\n","                x = Dropout(rate = self.discriminator_dropout_rate)(x)\r\n","\r\n","        # 마지막 합성곱 층 -> Flatten -> 평탄화 작업을 거쳐서 벡터화.\r\n","        # 이유? Dense 층에 들어가야 하므로.\r\n","        x = Flatten()(x)\r\n","        \r\n","        # Dense 층의 유닛의 갯수 : 1개\r\n","        # 이유? input인 이미지가 얼마나 진짜 이미지에 가까운지 확률값 1개만 출력하기 때문.\r\n","\r\n","        # 활성화함수 : sigmoid 함수\r\n","        # 이유? 0~1 사이의 값을 출력해주기 때문.\r\n","        discriminator_output = Dense(1, activation='sigmoid', kernel_initializer = self.weight_init)(x)\r\n","\r\n","        # keras의 Model : input layer, output layer를 받음.\r\n","        self.discriminator = Model(discriminator_input, discriminator_output)\r\n","\r\n","\r\n","    # generator(생성자) 생성\r\n","    # Dense, BatchNormalization, activation, Reshape, Dropout, UpSampling2D, Conv2D, Model\r\n","    # ------------------------------------------------------------------------\r\n","    # input : noise\r\n","    # output : image\r\n","    # ------------------------------------------------------------------------\r\n","    def _build_generator(self):\r\n","\r\n","        ### THE generator\r\n","\r\n","        # 입력받은 길이의 노이즈 벡터 생성\r\n","        generator_input = Input(shape=(self.z_dim,), name='generator_input')\r\n","\r\n","        x = generator_input\r\n","\r\n","        x = Dense(np.prod(self.generator_initial_dense_layer_size), kernel_initializer = self.weight_init)(x)\r\n","\r\n","        if self.generator_batch_norm_momentum:\r\n","            x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\r\n","\r\n","        x = self.get_activation(self.generator_activation)(x)\r\n","\r\n","        x = Reshape(self.generator_initial_dense_layer_size)(x)\r\n","\r\n","        if self.generator_dropout_rate:\r\n","            x = Dropout(rate = self.generator_dropout_rate)(x)\r\n","\r\n","        for i in range(self.n_layers_generator):\r\n","\r\n","            if self.generator_upsample[i] == 2:\r\n","                x = UpSampling2D()(x)\r\n","                x = Conv2D(\r\n","                    filters = self.generator_conv_filters[i]\r\n","                    , kernel_size = self.generator_conv_kernel_size[i]\r\n","                    , padding = 'same'\r\n","                    , name = 'generator_conv_' + str(i)\r\n","                    , kernel_initializer = self.weight_init\r\n","                )(x)\r\n","            else:\r\n","\r\n","                x = Conv2DTranspose(\r\n","                    filters = self.generator_conv_filters[i]\r\n","                    , kernel_size = self.generator_conv_kernel_size[i]\r\n","                    , padding = 'same'\r\n","                    , strides = self.generator_conv_strides[i]\r\n","                    , name = 'generator_conv_' + str(i)\r\n","                    , kernel_initializer = self.weight_init\r\n","                    )(x)\r\n","\r\n","            if i < self.n_layers_generator - 1:\r\n","\r\n","                if self.generator_batch_norm_momentum:\r\n","                    x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\r\n","\r\n","                x = self.get_activation(self.generator_activation)(x)\r\n","                    \r\n","                \r\n","            else:\r\n","                \r\n","                # 마지막 Conv2D 층 다음 활성화 함수 tanh 사용\r\n","                # 이유 ? 출력을 원본 이미지와 같은 -1 ~ 1 범위로 변환하기 위해서.\r\n","                x = Activation('tanh')(x)\r\n","\r\n","\r\n","        generator_output = x\r\n","\r\n","        self.generator = Model(generator_input, generator_output)\r\n","\r\n","       \r\n","    # optimiser 지정\r\n","    def get_opti(self, lr):\r\n","        if self.optimiser == 'adam':\r\n","            opti = Adam(lr=lr, beta_1=0.5)\r\n","        elif self.optimiser == 'rmsprop':\r\n","            opti = RMSprop(lr=lr)\r\n","        else:\r\n","            opti = Adam(lr=lr)\r\n","\r\n","        return opti\r\n","\r\n","\r\n","    def set_trainable(self, m, val):\r\n","        m.trainable = val\r\n","        for l in m.layers:\r\n","            l.trainable = val\r\n","\r\n","    # GAN 모델링\r\n","    def _build_adversarial(self):\r\n","        \r\n","        ### COMPILE DISCRIMINATOR\r\n","\r\n","        # target : 0, 1 -> 2개\r\n","        # 활성화 함수 : sigmoid\r\n","        # 출력층의 유닛의 갯수 : 1개\r\n","\r\n","        # -> binary_crossentropy 사용\r\n","        self.discriminator.compile(\r\n","        optimizer=self.get_opti(self.discriminator_learning_rate)  \r\n","        , loss = 'binary_crossentropy'\r\n","        ,  metrics = ['accuracy']\r\n","        )\r\n","        \r\n","        ### COMPILE THE FULL GAN\r\n","        \r\n","        # 생성자를 훈련하기 위한 모델 컴파일\r\n","        # 판별자의 가중치 동결 ; 컴파일한 판별자 모델이 영향을 받지 않도록 한다.\r\n","        self.set_trainable(self.discriminator, False)\r\n","\r\n","        # 잠재 공간 벡터 -> 생성자 -> 판별자 -> 확률 출력하는 모델 생성\r\n","        model_input = Input(shape=(self.z_dim,), name='model_input')\r\n","        model_output = self.discriminator(self.generator(model_input))\r\n","        self.model = Model(model_input, model_output)\r\n","\r\n","        # binary cross entropy를 이용하여 전체 모델을 compile.\r\n","        self.model.compile(optimizer=self.get_opti(self.generator_learning_rate) , loss='binary_crossentropy', metrics=['accuracy'])\r\n","\r\n","        self.set_trainable(self.discriminator, True)\r\n","\r\n","\r\n","\r\n","    # discriminator(판별자) 훈련\r\n","    # 판별자, 생성자 순서대로 훈련시킨다.\r\n","    def train_discriminator(self, x_train, batch_size, using_generator):\r\n","\r\n","        # 진짜 이미지의 target : 1\r\n","        valid = np.ones((batch_size,1))\r\n","        # 가짜 이미지의 target : 0\r\n","        fake = np.zeros((batch_size,1))\r\n","\r\n","        # 진짜 이미지로 훈련\r\n","        if using_generator:\r\n","            true_imgs = next(x_train)[0]  # iterator, next 사용\r\n","            if true_imgs.shape[0] != batch_size:\r\n","                true_imgs = next(x_train)[0]\r\n","        else:\r\n","            idx = np.random.randint(0, x_train.shape[0], batch_size)\r\n","            true_imgs = x_train[idx]\r\n","        \r\n","        # 가짜 이미지(생성된 이미지)로 훈련\r\n","        noise = np.random.normal(0, 1, (batch_size, self.z_dim))\r\n","        gen_imgs = self.generator.predict(noise)\r\n","\r\n","        d_loss_real, d_acc_real =   self.discriminator.train_on_batch(true_imgs, valid)\r\n","        d_loss_fake, d_acc_fake =   self.discriminator.train_on_batch(gen_imgs, fake)\r\n","        d_loss =  0.5 * (d_loss_real + d_loss_fake)\r\n","        d_acc = 0.5 * (d_acc_real + d_acc_fake)\r\n","\r\n","        return [d_loss, d_loss_real, d_loss_fake, d_acc, d_acc_real, d_acc_fake]\r\n","\r\n","    # generator(생성자) 훈련\r\n","    # 판별자 훈련시켰으니 이제 생성자를 훈련시킨다.\r\n","\r\n","    # 판별자의 가중치 : 동결되었으므로 변하지 X.\r\n","    # 생성자의 가중치 : 판별자가 1에 가까운 값으로 예측할 수 있는 이미지를 생성하는 방향으로 업데이트.\r\n","    def train_generator(self, batch_size):\r\n","        valid = np.ones((batch_size,1))\r\n","        noise = np.random.normal(0, 1, (batch_size, self.z_dim))\r\n","        return self.model.train_on_batch(noise, valid)\r\n","\r\n","\r\n","    def train(self, x_train, batch_size, epochs, run_folder\r\n","    , print_every_n_batches = 50\r\n","    , using_generator = False):\r\n","\r\n","        for epoch in range(self.epoch, self.epoch + epochs):\r\n","\r\n","            d = self.train_discriminator(x_train, batch_size, using_generator)\r\n","            g = self.train_generator(batch_size)\r\n","\r\n","            print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]\" % (epoch, d[0], d[1], d[2], d[3], d[4], d[5], g[0], g[1]))\r\n","\r\n","            self.d_losses.append(d)\r\n","            self.g_losses.append(g)\r\n","\r\n","            if epoch % print_every_n_batches == 0:\r\n","                self.sample_images(run_folder)\r\n","                self.model.save_weights(os.path.join(run_folder, 'weights/weights-%d.h5' % (epoch)))\r\n","                self.model.save_weights(os.path.join(run_folder, 'weights/weights.h5'))\r\n","                self.save_model(run_folder)\r\n","\r\n","            self.epoch += 1\r\n","\r\n","    \r\n","    def sample_images(self, run_folder):\r\n","        r, c = 5, 5\r\n","        noise = np.random.normal(0, 1, (r * c, self.z_dim))\r\n","        gen_imgs = self.generator.predict(noise)\r\n","\r\n","        gen_imgs = 0.5 * (gen_imgs + 1)\r\n","        gen_imgs = np.clip(gen_imgs, 0, 1)\r\n","\r\n","        fig, axs = plt.subplots(r, c, figsize=(15,15))\r\n","        cnt = 0\r\n","\r\n","        for i in range(r):\r\n","            for j in range(c):\r\n","                axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]), cmap = 'gray')\r\n","                axs[i,j].axis('off')\r\n","                cnt += 1\r\n","        fig.savefig(os.path.join(run_folder, \"images/sample_%d.png\" % self.epoch))\r\n","        plt.close()\r\n","\r\n","\r\n","\r\n","\r\n","    \r\n","    def plot_model(self, run_folder):\r\n","        plot_model(self.model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)\r\n","        plot_model(self.discriminator, to_file=os.path.join(run_folder ,'viz/discriminator.png'), show_shapes = True, show_layer_names = True)\r\n","        plot_model(self.generator, to_file=os.path.join(run_folder ,'viz/generator.png'), show_shapes = True, show_layer_names = True)\r\n","\r\n","\r\n","\r\n","    def save(self, folder):\r\n","\r\n","        with open(os.path.join(folder, 'params.pkl'), 'wb') as f:\r\n","            pkl.dump([\r\n","                self.input_dim\r\n","                , self.discriminator_conv_filters\r\n","                , self.discriminator_conv_kernel_size\r\n","                , self.discriminator_conv_strides\r\n","                , self.discriminator_batch_norm_momentum\r\n","                , self.discriminator_activation\r\n","                , self.discriminator_dropout_rate\r\n","                , self.discriminator_learning_rate\r\n","                , self.generator_initial_dense_layer_size\r\n","                , self.generator_upsample\r\n","                , self.generator_conv_filters\r\n","                , self.generator_conv_kernel_size\r\n","                , self.generator_conv_strides\r\n","                , self.generator_batch_norm_momentum\r\n","                , self.generator_activation\r\n","                , self.generator_dropout_rate\r\n","                , self.generator_learning_rate\r\n","                , self.optimiser\r\n","                , self.z_dim\r\n","                ], f)\r\n","\r\n","        self.plot_model(folder)\r\n","\r\n","    def save_model(self, run_folder):\r\n","        self.model.save(os.path.join(run_folder, 'model.h5'))\r\n","        self.discriminator.save(os.path.join(run_folder, 'discriminator.h5'))\r\n","        self.generator.save(os.path.join(run_folder, 'generator.h5'))\r\n","        pkl.dump(self, open( os.path.join(run_folder, \"obj.pkl\"), \"wb\" ))\r\n","\r\n","    def load_weights(self, filepath):\r\n","        self.model.load_weights(filepath)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtTJJdIBVI2r","executionInfo":{"status":"ok","timestamp":1607873949350,"user_tz":-540,"elapsed":7069,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}}},"source":["# gan 정의\r\n","gan = GAN(input_dim=(28, 28, 1),\r\n","          discriminator_conv_filters=[64, 64, 128, 128],\r\n","          discriminator_conv_kernel_size=[5, 5, 5, 5],\r\n","          discriminator_conv_strides=[2, 2, 2, 1],\r\n","          discriminator_batch_norm_momentum=None,\r\n","          discriminator_activation=\"relu\",\r\n","          discriminator_dropout_rate=0.4,\r\n","          discriminator_learning_rate=0.0008,\r\n","          generator_initial_dense_layer_size=(7, 7, 64),\r\n","          generator_upsample=[2, 2, 1, 1],\r\n","          generator_conv_filters=[128, 64, 64, 1],\r\n","          generator_conv_kernel_size=[5, 5, 5, 5],\r\n","          generator_conv_strides=[1, 1, 1, 1],\r\n","          generator_batch_norm_momentum=0.9,\r\n","          generator_activation=\"relu\",\r\n","          generator_dropout_rate=None,\r\n","          generator_learning_rate=0.0004,\r\n","          optimiser=\"rmsprop\",\r\n","          z_dim=100)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DUskcJjVdkIB"},"source":["# 판별자(discriminator)\r\n","- input : image\r\n","- output : 진짜 이미지일 확률. 0~1 사이의 값.\r\n","- 목표 : 이미지가 진짜인지/가짜인지 예측.\r\n","- 지도 학습, 이미지 분류 문제\r\n","- 합성곱 층 포함되어있음(convolution layer)\r\n","- 배치 정규화 많이 사용"]},{"cell_type":"markdown","metadata":{"id":"JyQRX9qOf-iA"},"source":["# 생성자(generator)\r\n","- input : 다변수 표준 정규분포에서 추출한 벡터. 정해진 차원의 잠재 공간 벡터.\r\n","- output : 원본 훈련 데이터의 이미지와 동일한 크기의 이미지\r\n","- 잠재 공간의 벡터를 조작하여 원본 차원에 있는 이미지의 고수준 특성을 바꿀 수 있는 점에서 VAE(변이형 오토인코더)의 디코더와 비슷한 특징을 가지고 있다."]},{"cell_type":"markdown","metadata":{"id":"8XyJxFsWjUGj"},"source":["# 업샘플링(upsampling) 층\r\n","- keras의 UpSampling2D 층을 사용하여 tensor의 높이, 너비를 2배로 늘린다.\r\n","- 단순히 입력의 각 행과 열을 반복하여 크기를 두 배로 만든다.\r\n","- 픽셀 사이 공간을 0으로 채우는 것X, 기존 픽셀값을 사용해 업샘플링\r\n","- Conv2DTranspose와 UpSampling2D 방식 모두를 시도해보고 어떤 것이 가장 잘 맞는 지 확인할 것."]},{"cell_type":"markdown","metadata":{"id":"Zl2BUOOTmQfn"},"source":["# GAN 훈련\r\n","- 훈련 데이터셋에서 진짜 샘플을 랜덤하게 선택 & 생성자의 출력을 합쳐서 훈련 세트를 만들어서 판별자를 훈련시킨다.\r\n","- label : 진짜(1), 가짜(0)\r\n","- 진짜 이미지에 대해서는 1에 가까운 값을 출력, 가짜 이미지에 대해서는 0에 가까운 값을 출력하도록 훈련\r\n","- 진짜 이미지가 잠재 공간의 어떤 포인트에 매핑되는 지 알려주는 훈련 세트가 X -> 생성자 훈련 어렵다. -> 판별자의 출력값이 1에 가까워지도록 훈련시켜야 한다.\r\n","- 전체 모델을 훈련할 때 생성자의 가중치만 업데이트되도록, 판별자의 가중치를 동결하는 것이 중요하다.\r\n","- 판별자의 가중치를 동결하지 X ? -> 생성된 이미지를 진짜라고 여기도록 조종됨.\r\n","- 학습률 : GAN에서 주의 깊게 튜닝해야 하는 파라미터!"]},{"cell_type":"markdown","metadata":{"id":"gw3njZgDq4qz"},"source":["# 손실 함수(loss function)\r\n","- binary cross entropy 사용"]},{"cell_type":"markdown","metadata":{"id":"ppZDagwwrHDf"},"source":["GAN을 활용하면 고수준 특성을 스스로 만들 수 있다.\r\n","\r\n","고수준 특성을 구성하기 위해 필수적인 픽셀 사이의 상호 의존 관계를 모델링할 수 있다."]},{"cell_type":"code","metadata":{"id":"JopGpTDgvC7F","executionInfo":{"status":"ok","timestamp":1607873949971,"user_tz":-540,"elapsed":7686,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}}},"source":[""],"execution_count":18,"outputs":[]}]}