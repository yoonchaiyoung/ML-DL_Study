{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN(생성적 적대 신경망).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPeBOzSm582/eFp4mu2pPvS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gYgvqbGvFvzM"},"source":["참고 : Generative Deep Learning 미술관에 GAN 딥러닝 실전 프로젝트 - 데이비드 포스터 지음 (출판사 : 한빛미디어)\r\n","\r\n","참고 : https://sunghan-kim.github.io/ml/3min-dl-ch09/"]},{"cell_type":"markdown","metadata":{"id":"rbEECPhMBcLE"},"source":["# GAN(Generative Adversarial Network) : 생성적 적대 신경망\r\n","- 생성자(generator), 판별자(discriminator) 네트워크 2개가 경쟁하는 것\r\n","- 생성자 : 원본 데이터셋에서 샘플링한 것처럼 보이는 샘플로 변환 (진짜같은 가짜 생성)\r\n","- 판별자 : 원본 데이터셋에서 추출한 샘플인지 생성자가 만든 가짜인지를 구별 (진짜인지, 가짜인지 구별)\r\n","- <img src=\"https://1.bp.blogspot.com/-n9mKBe3m9zw/WZkBAS_oUcI/AAAAAAAAAIU/WKIHqZp7z_IvQ-arRsEvWDp8C8foPDc2wCLcBGAs/s1600/6.png\" width=600>\r\n","- 생성자는 더 진짜같은 가짜를 만들어내고, 판별자는 정확하게 진짜와 가짜를 구별하는 능력을 유지하도록 학습한다."]},{"cell_type":"code","metadata":{"id":"gfqQPt--UL6G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607926211272,"user_tz":-540,"elapsed":105216,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}},"outputId":"21de814d-eb49-431b-a566-be832268c234"},"source":["# 구글 드라이브 import\r\n","from google.colab import drive\r\n","drive.mount(\"/content/drive\")\r\n","\r\n","# 기본 환경 설정\r\n","!git clone https://github.com/rickiepark/GDL_code.git\r\n","!git pull\r\n","!conda create -n generative python=3.6 ipykernel\r\n","!pip install virtualenv virtualenvwrapper\r\n","!mkvirtualenv generative\r\n","!pip install absl-py appnope backcall bleach cloudpickle cycler dask decorator defusedxml entrypoints gast grpcio h5py ipykernel ipython ipython-genutils ipywidgets jedi Jinja2 jsonschema jupyter jupyter-client jupyter-console jupyter-core Keras Keras-Applications Keras-Preprocessing kiwisolver Markdown MarkupSafe matplotlib mistune music21 nbconvert nbformat networkx notebook numpy pandas pandocfilters parso pexpect pickleshare Pillow prometheus-client prompt-toolkit protobuf ptyprocess pydot Pygments pyparsing python-dateutil pytz PyWavelets PyYAML pyzmq qtconsole scikit-image scipy Send2Trash six tensorboard tensorflow termcolor terminado testpath toolz tornado traitlets wcwidth webencodings Werkzeug widgetsnbextension"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Cloning into 'GDL_code'...\n","remote: Enumerating objects: 480, done.\u001b[K\n","remote: Total 480 (delta 0), reused 0 (delta 0), pack-reused 480\u001b[K\n","Receiving objects: 100% (480/480), 178.48 MiB | 32.11 MiB/s, done.\n","Resolving deltas: 100% (224/224), done.\n","Checking out files: 100% (77/77), done.\n","fatal: not a git repository (or any of the parent directories): .git\n","/bin/bash: conda: command not found\n","Collecting virtualenv\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/c6/bb564f5eec616d241e85d741f00a07f5f50ea12989022ad49bc66876993c/virtualenv-20.2.2-py2.py3-none-any.whl (5.7MB)\n","\u001b[K     |████████████████████████████████| 5.7MB 8.7MB/s \n","\u001b[?25hCollecting virtualenvwrapper\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/6b/2f05d73b2d2f2410b48b90d3783a0034c26afa534a4a95ad5f1178d61191/virtualenvwrapper-4.8.4.tar.gz (334kB)\n","\u001b[K     |████████████████████████████████| 337kB 43.8MB/s \n","\u001b[?25hRequirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv) (1.15.0)\n","Collecting distlib<1,>=0.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/0a/490fa011d699bb5a5f3a0cf57de82237f52a6db9d40f33c53b2736c9a1f9/distlib-0.3.1-py2.py3-none-any.whl (335kB)\n","\u001b[K     |████████████████████████████████| 337kB 51.8MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from virtualenv) (3.1.1)\n","Requirement already satisfied: importlib-resources>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from virtualenv) (3.3.0)\n","Collecting appdirs<2,>=1.4.3\n","  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: filelock<4,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv) (3.0.12)\n","Collecting virtualenv-clone\n","  Downloading https://files.pythonhosted.org/packages/83/b8/cd931487d250565392c39409117436d910232c8a3ac09ea2fb62a6c47bff/virtualenv_clone-0.5.4-py2.py3-none-any.whl\n","Collecting stevedore\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->virtualenv) (3.4.0)\n","Collecting pbr!=2.1.0,>=2.0.0\n","  Using cached https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl\n","Building wheels for collected packages: virtualenvwrapper\n","  Building wheel for virtualenvwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for virtualenvwrapper: filename=virtualenvwrapper-4.8.4-py2.py3-none-any.whl size=24849 sha256=7ca6ed148e8d7f73a82be13b66b67d63fbefc65275e87847d51dd12578f24775\n","  Stored in directory: /root/.cache/pip/wheels/70/d7/39/a522e494b0e145a1bec42f45a6e542f097c20d0be3ec26866e\n","Successfully built virtualenvwrapper\n","Installing collected packages: distlib, appdirs, virtualenv, virtualenv-clone, pbr, stevedore, virtualenvwrapper\n","Successfully installed appdirs-1.4.4 distlib-0.3.1 pbr-5.5.1 stevedore-3.3.0 virtualenv-20.2.2 virtualenv-clone-0.5.4 virtualenvwrapper-4.8.4\n","/bin/bash: mkvirtualenv: command not found\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (0.10.0)\n","Collecting appnope\n","  Downloading https://files.pythonhosted.org/packages/e4/fa/0c6c9786aa6927d12d100d322588e125e6ed466ab0a3d2d509ea18aeb56d/appnope-0.1.2-py2.py3-none-any.whl\n","Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (0.2.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (3.2.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (1.3.0)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (0.10.0)\n","Requirement already satisfied: dask in /usr/local/lib/python3.6/dist-packages (2.12.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (4.4.2)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (0.6.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (0.3)\n","Requirement already satisfied: gast in /usr/local/lib/python3.6/dist-packages (0.3.3)\n","Requirement already satisfied: grpcio in /usr/local/lib/python3.6/dist-packages (1.34.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (4.10.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (5.5.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (0.2.0)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (7.5.1)\n","Requirement already satisfied: jedi in /usr/local/lib/python3.6/dist-packages (0.17.2)\n","Requirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (2.11.2)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (2.6.0)\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (5.3.5)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (5.2.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (4.7.0)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n","Collecting Keras-Applications\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n","\u001b[?25hRequirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.6/dist-packages (1.1.2)\n","Requirement already satisfied: kiwisolver in /usr/local/lib/python3.6/dist-packages (1.3.1)\n","Requirement already satisfied: Markdown in /usr/local/lib/python3.6/dist-packages (3.3.3)\n","Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (1.1.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n","Requirement already satisfied: mistune in /usr/local/lib/python3.6/dist-packages (0.8.4)\n","Requirement already satisfied: music21 in /usr/local/lib/python3.6/dist-packages (5.5.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (5.6.1)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (5.0.8)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (2.5)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (5.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n","Requirement already satisfied: pandocfilters in /usr/local/lib/python3.6/dist-packages (1.4.3)\n","Requirement already satisfied: parso in /usr/local/lib/python3.6/dist-packages (0.7.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.6/dist-packages (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (0.7.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (0.9.0)\n","Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.6/dist-packages (1.0.18)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (3.12.4)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.6/dist-packages (0.6.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n","Requirement already satisfied: Pygments in /usr/local/lib/python3.6/dist-packages (2.6.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (2.4.7)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (2.8.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (2018.9)\n","Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (1.1.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (3.13)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (20.0.0)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (5.0.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (1.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.15.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: terminado in /usr/local/lib/python3.6/dist-packages (0.9.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (0.4.4)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (0.11.1)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (5.1.1)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (4.3.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (0.2.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Requirement already satisfied: Werkzeug in /usr/local/lib/python3.6/dist-packages (1.0.1)\n","Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.6/dist-packages (3.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach) (20.7)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython) (50.3.2)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython) (0.8.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from Markdown) (3.1.1)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole) (1.9.0)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (2.23.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.17.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.7.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.4.2)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.36.1)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->Markdown) (3.4.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n","Installing collected packages: appnope, Keras-Applications\n","Successfully installed Keras-Applications-1.0.8 appnope-0.1.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9PshFuxfFJKr"},"source":["# 애니멀간 데이터\r\n","- 28x28 픽셀, 흑백 낙서 이미지 데이터\r\n","- 주제별로 labeling 되어있음"]},{"cell_type":"markdown","metadata":{"id":"CoH1CZ_SVF0A"},"source":["# GAN 모델링"]},{"cell_type":"code","metadata":{"id":"t_EzsWACW_gx","executionInfo":{"status":"ok","timestamp":1607926213382,"user_tz":-540,"elapsed":107316,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}}},"source":["# GAN class 정의\r\n","\r\n","from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\r\n","# from keras.layers.merge import _Merge\r\n","# keras 2.x 버전에서는 작동 안 함\r\n","# 대신에 Add나 concatenate 사용\r\n","from keras.layers import Add, Concatenate\r\n","\r\n","from keras.models import Model, Sequential\r\n","from keras import backend as K\r\n","from keras.optimizers import Adam, RMSprop\r\n","from keras.utils import plot_model\r\n","from keras.initializers import RandomNormal\r\n","\r\n","import numpy as np\r\n","import json\r\n","import os\r\n","import pickle as pkl\r\n","import matplotlib.pyplot as plt\r\n","\r\n","def concatenate(x1, x2):\r\n","  merged = Concatenate([x1, x2])\r\n","  return merged\r\n","\r\n","class GAN():\r\n","  # parameter 설정, model build, compile\r\n","    def __init__(self\r\n","        , input_dim\r\n","        , discriminator_conv_filters\r\n","        , discriminator_conv_kernel_size\r\n","        , discriminator_conv_strides\r\n","        , discriminator_batch_norm_momentum\r\n","        , discriminator_activation\r\n","        , discriminator_dropout_rate\r\n","        , discriminator_learning_rate\r\n","        , generator_initial_dense_layer_size\r\n","        , generator_upsample\r\n","        , generator_conv_filters\r\n","        , generator_conv_kernel_size\r\n","        , generator_conv_strides\r\n","        , generator_batch_norm_momentum\r\n","        , generator_activation\r\n","        , generator_dropout_rate\r\n","        , generator_learning_rate\r\n","        , optimiser\r\n","        , z_dim\r\n","        ):\r\n","\r\n","        self.name = 'gan'\r\n","\r\n","        # 파라미터 초기화\r\n","        self.input_dim = input_dim\r\n","        self.discriminator_conv_filters = discriminator_conv_filters\r\n","        self.discriminator_conv_kernel_size = discriminator_conv_kernel_size\r\n","        self.discriminator_conv_strides = discriminator_conv_strides\r\n","        self.discriminator_batch_norm_momentum = discriminator_batch_norm_momentum\r\n","        self.discriminator_activation = discriminator_activation\r\n","        self.discriminator_dropout_rate = discriminator_dropout_rate\r\n","        self.discriminator_learning_rate = discriminator_learning_rate\r\n","\r\n","        self.generator_initial_dense_layer_size = generator_initial_dense_layer_size\r\n","        self.generator_upsample = generator_upsample\r\n","        self.generator_conv_filters = generator_conv_filters\r\n","        self.generator_conv_kernel_size = generator_conv_kernel_size\r\n","        self.generator_conv_strides = generator_conv_strides\r\n","        self.generator_batch_norm_momentum = generator_batch_norm_momentum\r\n","        self.generator_activation = generator_activation\r\n","        self.generator_dropout_rate = generator_dropout_rate\r\n","        self.generator_learning_rate = generator_learning_rate\r\n","        \r\n","        self.optimiser = optimiser\r\n","        self.z_dim = z_dim\r\n","\r\n","        # discriminator, generator의 layer 갯수\r\n","        self.n_layers_discriminator = len(discriminator_conv_filters)\r\n","        self.n_layers_generator = len(generator_conv_filters)\r\n","\r\n","        # 정규분포로 초깃값 설정\r\n","        self.weight_init = RandomNormal(mean=0., stddev=0.02)\r\n","\r\n","        self.d_losses = []\r\n","        self.g_losses = []\r\n","\r\n","        self.epoch = 0\r\n","\r\n","        # discriminator, generator 모델 생성 메소드\r\n","        self._build_discriminator()\r\n","        self._build_generator()\r\n","\r\n","        self._build_adversarial()\r\n","\r\n","    # 활성화 함수 지정\r\n","    def get_activation(self, activation):\r\n","        if activation == 'leaky_relu':\r\n","            layer = LeakyReLU(alpha = 0.2)\r\n","        else:\r\n","            layer = Activation(activation)\r\n","        return layer\r\n","\r\n","    # discriminator(판별자) 생성\r\n","    # Conv2D, BatchNormalization, activation, Dropout, Flatten, Dense, Model\r\n","    # ------------------------------------------------------------------------\r\n","    # input : image\r\n","    # output : 진짜 이미지일 확률. 0~1 사이의 값.\r\n","    # ------------------------------------------------------------------------\r\n","    def _build_discriminator(self):\r\n","\r\n","        ### THE discriminator\r\n","        discriminator_input = Input(shape=self.input_dim, name='discriminator_input')  # discriminator의 input 정의\r\n","\r\n","        x = discriminator_input\r\n","\r\n","        # 합성곱 층(convolution layer) 쌓기\r\n","        for i in range(self.n_layers_discriminator):\r\n","\r\n","            x = Conv2D(\r\n","                filters = self.discriminator_conv_filters[i]\r\n","                , kernel_size = self.discriminator_conv_kernel_size[i]\r\n","                , strides = self.discriminator_conv_strides[i]\r\n","                , padding = 'same'\r\n","                , name = 'discriminator_conv_' + str(i)\r\n","                , kernel_initializer = self.weight_init\r\n","                )(x)\r\n","\r\n","            if self.discriminator_batch_norm_momentum and i > 0:\r\n","                x = BatchNormalization(momentum = self.discriminator_batch_norm_momentum)(x)\r\n","\r\n","            x = self.get_activation(self.discriminator_activation)(x)\r\n","\r\n","            if self.discriminator_dropout_rate:\r\n","                x = Dropout(rate = self.discriminator_dropout_rate)(x)\r\n","\r\n","        # 마지막 합성곱 층 -> Flatten -> 평탄화 작업을 거쳐서 벡터화.\r\n","        # 이유? Dense 층에 들어가야 하므로.\r\n","        x = Flatten()(x)\r\n","        \r\n","        # Dense 층의 유닛의 갯수 : 1개\r\n","        # 이유? input인 이미지가 얼마나 진짜 이미지에 가까운지 확률값 1개만 출력하기 때문.\r\n","\r\n","        # 활성화함수 : sigmoid 함수\r\n","        # 이유? 0~1 사이의 값을 출력해주기 때문.\r\n","        discriminator_output = Dense(1, activation='sigmoid', kernel_initializer = self.weight_init)(x)\r\n","\r\n","        # keras의 Model : input layer, output layer를 받음.\r\n","        self.discriminator = Model(discriminator_input, discriminator_output)\r\n","\r\n","\r\n","    # generator(생성자) 생성\r\n","    # Dense, BatchNormalization, activation, Reshape, Dropout, UpSampling2D, Conv2D, Model\r\n","    # ------------------------------------------------------------------------\r\n","    # input : noise\r\n","    # output : image\r\n","    # ------------------------------------------------------------------------\r\n","    def _build_generator(self):\r\n","\r\n","        ### THE generator\r\n","\r\n","        # 입력받은 길이의 노이즈 벡터 생성\r\n","        generator_input = Input(shape=(self.z_dim,), name='generator_input')\r\n","\r\n","        x = generator_input\r\n","\r\n","        x = Dense(np.prod(self.generator_initial_dense_layer_size), kernel_initializer = self.weight_init)(x)\r\n","\r\n","        if self.generator_batch_norm_momentum:\r\n","            x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\r\n","\r\n","        x = self.get_activation(self.generator_activation)(x)\r\n","\r\n","        x = Reshape(self.generator_initial_dense_layer_size)(x)\r\n","\r\n","        if self.generator_dropout_rate:\r\n","            x = Dropout(rate = self.generator_dropout_rate)(x)\r\n","\r\n","        for i in range(self.n_layers_generator):\r\n","\r\n","            if self.generator_upsample[i] == 2:\r\n","                x = UpSampling2D()(x)\r\n","                x = Conv2D(\r\n","                    filters = self.generator_conv_filters[i]\r\n","                    , kernel_size = self.generator_conv_kernel_size[i]\r\n","                    , padding = 'same'\r\n","                    , name = 'generator_conv_' + str(i)\r\n","                    , kernel_initializer = self.weight_init\r\n","                )(x)\r\n","            else:\r\n","\r\n","                x = Conv2DTranspose(\r\n","                    filters = self.generator_conv_filters[i]\r\n","                    , kernel_size = self.generator_conv_kernel_size[i]\r\n","                    , padding = 'same'\r\n","                    , strides = self.generator_conv_strides[i]\r\n","                    , name = 'generator_conv_' + str(i)\r\n","                    , kernel_initializer = self.weight_init\r\n","                    )(x)\r\n","\r\n","            if i < self.n_layers_generator - 1:\r\n","\r\n","                if self.generator_batch_norm_momentum:\r\n","                    x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\r\n","\r\n","                x = self.get_activation(self.generator_activation)(x)\r\n","                    \r\n","                \r\n","            else:\r\n","                \r\n","                # 마지막 Conv2D 층 다음 활성화 함수 tanh 사용\r\n","                # 이유 ? 출력을 원본 이미지와 같은 -1 ~ 1 범위로 변환하기 위해서.\r\n","                x = Activation('tanh')(x)\r\n","\r\n","\r\n","        generator_output = x\r\n","\r\n","        self.generator = Model(generator_input, generator_output)\r\n","\r\n","       \r\n","    # optimiser 지정\r\n","    def get_opti(self, lr):\r\n","        if self.optimiser == 'adam':\r\n","            opti = Adam(lr=lr, beta_1=0.5)\r\n","        elif self.optimiser == 'rmsprop':\r\n","            opti = RMSprop(lr=lr)\r\n","        else:\r\n","            opti = Adam(lr=lr)\r\n","\r\n","        return opti\r\n","\r\n","\r\n","    def set_trainable(self, m, val):\r\n","        m.trainable = val\r\n","        for l in m.layers:\r\n","            l.trainable = val\r\n","\r\n","    # GAN 모델링\r\n","    def _build_adversarial(self):\r\n","        \r\n","        ### COMPILE DISCRIMINATOR\r\n","\r\n","        # target : 0, 1 -> 2개\r\n","        # 활성화 함수 : sigmoid\r\n","        # 출력층의 유닛의 갯수 : 1개\r\n","\r\n","        # -> binary_crossentropy 사용\r\n","        self.discriminator.compile(\r\n","        optimizer=self.get_opti(self.discriminator_learning_rate)  \r\n","        , loss = 'binary_crossentropy'\r\n","        ,  metrics = ['accuracy']\r\n","        )\r\n","        \r\n","        ### COMPILE THE FULL GAN\r\n","        \r\n","        # 생성자를 훈련하기 위한 모델 컴파일\r\n","        # 판별자의 가중치 동결 ; 컴파일한 판별자 모델이 영향을 받지 않도록 한다.\r\n","        self.set_trainable(self.discriminator, False)\r\n","\r\n","        # 잠재 공간 벡터 -> 생성자 -> 판별자 -> 확률 출력하는 모델 생성\r\n","        model_input = Input(shape=(self.z_dim,), name='model_input')\r\n","        model_output = self.discriminator(self.generator(model_input))\r\n","        self.model = Model(model_input, model_output)\r\n","\r\n","        # binary cross entropy를 이용하여 전체 모델을 compile.\r\n","        self.model.compile(optimizer=self.get_opti(self.generator_learning_rate) , loss='binary_crossentropy', metrics=['accuracy'])\r\n","\r\n","        self.set_trainable(self.discriminator, True)\r\n","\r\n","\r\n","\r\n","    # discriminator(판별자) 훈련\r\n","    # 판별자, 생성자 순서대로 훈련시킨다.\r\n","    def train_discriminator(self, x_train, batch_size, using_generator):\r\n","\r\n","        # 진짜 이미지의 target : 1\r\n","        valid = np.ones((batch_size,1))\r\n","        # 가짜 이미지의 target : 0\r\n","        fake = np.zeros((batch_size,1))\r\n","\r\n","        # 진짜 이미지로 훈련\r\n","        if using_generator:\r\n","            true_imgs = next(x_train)[0]  # iterator, next 사용\r\n","            if true_imgs.shape[0] != batch_size:\r\n","                true_imgs = next(x_train)[0]\r\n","        else:\r\n","            idx = np.random.randint(0, x_train.shape[0], batch_size)\r\n","            true_imgs = x_train[idx]\r\n","        \r\n","        # 가짜 이미지(생성된 이미지)로 훈련\r\n","        noise = np.random.normal(0, 1, (batch_size, self.z_dim))\r\n","        gen_imgs = self.generator.predict(noise)\r\n","\r\n","        d_loss_real, d_acc_real =   self.discriminator.train_on_batch(true_imgs, valid)\r\n","        d_loss_fake, d_acc_fake =   self.discriminator.train_on_batch(gen_imgs, fake)\r\n","        d_loss =  0.5 * (d_loss_real + d_loss_fake)\r\n","        d_acc = 0.5 * (d_acc_real + d_acc_fake)\r\n","\r\n","        return [d_loss, d_loss_real, d_loss_fake, d_acc, d_acc_real, d_acc_fake]\r\n","\r\n","    # generator(생성자) 훈련\r\n","    # 판별자 훈련시켰으니 이제 생성자를 훈련시킨다.\r\n","\r\n","    # 판별자의 가중치 : 동결되었으므로 변하지 X.\r\n","    # 생성자의 가중치 : 판별자가 1에 가까운 값으로 예측할 수 있는 이미지를 생성하는 방향으로 업데이트.\r\n","    def train_generator(self, batch_size):\r\n","        valid = np.ones((batch_size,1))\r\n","        noise = np.random.normal(0, 1, (batch_size, self.z_dim))\r\n","        return self.model.train_on_batch(noise, valid)\r\n","\r\n","\r\n","    def train(self, x_train, batch_size, epochs, run_folder\r\n","    , print_every_n_batches = 50\r\n","    , using_generator = False):\r\n","\r\n","        for epoch in range(self.epoch, self.epoch + epochs):\r\n","\r\n","            d = self.train_discriminator(x_train, batch_size, using_generator)\r\n","            g = self.train_generator(batch_size)\r\n","\r\n","            print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]\" % (epoch, d[0], d[1], d[2], d[3], d[4], d[5], g[0], g[1]))\r\n","\r\n","            self.d_losses.append(d)\r\n","            self.g_losses.append(g)\r\n","\r\n","            if epoch % print_every_n_batches == 0:\r\n","                self.sample_images(run_folder)\r\n","                self.model.save_weights(os.path.join(run_folder, 'weights/weights-%d.h5' % (epoch)))\r\n","                self.model.save_weights(os.path.join(run_folder, 'weights/weights.h5'))\r\n","                self.save_model(run_folder)\r\n","\r\n","            self.epoch += 1\r\n","\r\n","    \r\n","    def sample_images(self, run_folder):\r\n","        r, c = 5, 5\r\n","        noise = np.random.normal(0, 1, (r * c, self.z_dim))\r\n","        gen_imgs = self.generator.predict(noise)\r\n","\r\n","        gen_imgs = 0.5 * (gen_imgs + 1)\r\n","        gen_imgs = np.clip(gen_imgs, 0, 1)\r\n","\r\n","        fig, axs = plt.subplots(r, c, figsize=(15,15))\r\n","        cnt = 0\r\n","\r\n","        for i in range(r):\r\n","            for j in range(c):\r\n","                axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]), cmap = 'gray')\r\n","                axs[i,j].axis('off')\r\n","                cnt += 1\r\n","        fig.savefig(os.path.join(run_folder, \"images/sample_%d.png\" % self.epoch))\r\n","        plt.close()\r\n","\r\n","\r\n","\r\n","\r\n","    \r\n","    def plot_model(self, run_folder):\r\n","        plot_model(self.model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)\r\n","        plot_model(self.discriminator, to_file=os.path.join(run_folder ,'viz/discriminator.png'), show_shapes = True, show_layer_names = True)\r\n","        plot_model(self.generator, to_file=os.path.join(run_folder ,'viz/generator.png'), show_shapes = True, show_layer_names = True)\r\n","\r\n","\r\n","\r\n","    def save(self, folder):\r\n","\r\n","        with open(os.path.join(folder, 'params.pkl'), 'wb') as f:\r\n","            pkl.dump([\r\n","                self.input_dim\r\n","                , self.discriminator_conv_filters\r\n","                , self.discriminator_conv_kernel_size\r\n","                , self.discriminator_conv_strides\r\n","                , self.discriminator_batch_norm_momentum\r\n","                , self.discriminator_activation\r\n","                , self.discriminator_dropout_rate\r\n","                , self.discriminator_learning_rate\r\n","                , self.generator_initial_dense_layer_size\r\n","                , self.generator_upsample\r\n","                , self.generator_conv_filters\r\n","                , self.generator_conv_kernel_size\r\n","                , self.generator_conv_strides\r\n","                , self.generator_batch_norm_momentum\r\n","                , self.generator_activation\r\n","                , self.generator_dropout_rate\r\n","                , self.generator_learning_rate\r\n","                , self.optimiser\r\n","                , self.z_dim\r\n","                ], f)\r\n","\r\n","        self.plot_model(folder)\r\n","\r\n","    def save_model(self, run_folder):\r\n","        self.model.save(os.path.join(run_folder, 'model.h5'))\r\n","        self.discriminator.save(os.path.join(run_folder, 'discriminator.h5'))\r\n","        self.generator.save(os.path.join(run_folder, 'generator.h5'))\r\n","        pkl.dump(self, open( os.path.join(run_folder, \"obj.pkl\"), \"wb\" ))\r\n","\r\n","    def load_weights(self, filepath):\r\n","        self.model.load_weights(filepath)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtTJJdIBVI2r","executionInfo":{"status":"ok","timestamp":1607926219182,"user_tz":-540,"elapsed":113111,"user":{"displayName":"윤채영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjzVSEIYGpvGvlUmbyWCmOdOr9J_OFxud0d-wW=s64","userId":"05705444561123045578"}}},"source":["# gan 정의\r\n","gan = GAN(input_dim=(28, 28, 1),\r\n","          discriminator_conv_filters=[64, 64, 128, 128],\r\n","          discriminator_conv_kernel_size=[5, 5, 5, 5],\r\n","          discriminator_conv_strides=[2, 2, 2, 1],\r\n","          discriminator_batch_norm_momentum=None,\r\n","          discriminator_activation=\"relu\",\r\n","          discriminator_dropout_rate=0.4,\r\n","          discriminator_learning_rate=0.0008,\r\n","          generator_initial_dense_layer_size=(7, 7, 64),\r\n","          generator_upsample=[2, 2, 1, 1],\r\n","          generator_conv_filters=[128, 64, 64, 1],\r\n","          generator_conv_kernel_size=[5, 5, 5, 5],\r\n","          generator_conv_strides=[1, 1, 1, 1],\r\n","          generator_batch_norm_momentum=0.9,\r\n","          generator_activation=\"relu\",\r\n","          generator_dropout_rate=None,\r\n","          generator_learning_rate=0.0004,\r\n","          optimiser=\"rmsprop\",\r\n","          z_dim=100)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DUskcJjVdkIB"},"source":["# 판별자(discriminator)\r\n","- input : image\r\n","- output : 진짜 이미지일 확률. 0~1 사이의 값.\r\n","- 목표 : 이미지가 진짜인지/가짜인지 예측.\r\n","- 지도 학습, 이미지 분류 문제\r\n","- 합성곱 층 포함되어있음(convolution layer)\r\n","- 배치 정규화 많이 사용\r\n","- 판별의 정확도를 최대화하는 것이 목적이다!"]},{"cell_type":"markdown","metadata":{"id":"JyQRX9qOf-iA"},"source":["# 생성자(generator)\r\n","- input : 다변수 표준 정규분포에서 추출한 벡터. 정해진 차원의 잠재 공간 벡터.\r\n","- output : 원본 훈련 데이터의 이미지와 동일한 크기의 이미지\r\n","- 잠재 공간의 벡터를 조작하여 원본 차원에 있는 이미지의 고수준 특성을 바꿀 수 있는 점에서 VAE(변이형 오토인코더)의 디코더와 비슷한 특징을 가지고 있다.\r\n","- 판별자의 정확도를 최소화하는 것이 목적이다!"]},{"cell_type":"markdown","metadata":{"id":"8XyJxFsWjUGj"},"source":["# 업샘플링(upsampling) 층\r\n","- keras의 UpSampling2D 층을 사용하여 tensor의 높이, 너비를 2배로 늘린다.\r\n","- 단순히 입력의 각 행과 열을 반복하여 크기를 두 배로 만든다.\r\n","- 픽셀 사이 공간을 0으로 채우는 것X, 기존 픽셀값을 사용해 업샘플링\r\n","- Conv2DTranspose와 UpSampling2D 방식 모두를 시도해보고 어떤 것이 가장 잘 맞는 지 확인할 것."]},{"cell_type":"markdown","metadata":{"id":"gw3njZgDq4qz"},"source":["# 손실 함수(loss function) = 목적 함수(objective function)\r\n","- binary cross entropy 사용"]},{"cell_type":"markdown","metadata":{"id":"ppZDagwwrHDf"},"source":["GAN을 활용하면 고수준 특성을 스스로 만들 수 있다.\r\n","\r\n","고수준 특성을 구성하기 위해 필수적인 픽셀 사이의 상호 의존 관계를 모델링할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"Zl2BUOOTmQfn"},"source":["# GAN 훈련\r\n","- 훈련 데이터셋에서 진짜 샘플을 랜덤하게 선택 & 생성자의 출력을 합쳐서 훈련 세트를 만들어서 판별자를 훈련시킨다.\r\n","- label : 진짜(1), 가짜(0)\r\n","- 진짜 이미지에 대해서는 1에 가까운 값을 출력, 가짜 이미지에 대해서는 0에 가까운 값을 출력하도록 훈련\r\n","- 진짜 이미지가 잠재 공간의 어떤 포인트에 매핑되는 지 알려주는 훈련 세트가 X -> 생성자 훈련 어렵다. -> 판별자의 출력값이 1에 가까워지도록 훈련시켜야 한다.\r\n","- 전체 모델을 훈련할 때 생성자의 가중치만 업데이트되도록, 판별자의 가중치를 동결하는 것이 중요하다.\r\n","- 판별자의 가중치를 동결하지 X ? -> 생성된 이미지를 진짜라고 여기도록 조종됨.\r\n","- 학습률 : GAN에서 주의 깊게 튜닝해야 하는 파라미터!\r\n","\r\n","훈련 순서\r\n","1. 판별자 네트워크 학습\r\n","- 랜덤 노이즈 m개 -> 생성자 네트워크 -> 변환된 가짜 이미지 m개\r\n","- 훈련 데이터셋에서 진짜 이미지 m개 선택\r\n","- 2m개의 데이터(진짜 m개 + 가짜 m개)를 이용 -> 판별자 네트워크의 정확도를 최대화하는 방법으로 학습\r\n","\r\n","2. 생성자 네트워크 학습\r\n","- 랜덤 노이즈 m개 생성\r\n","- m개의 데이터를 이용 -> 생성자가 판별자의 정확도를 최소화하도록 학습\r\n","\r\n","1,2 의 순서를 반복\r\n","\r\n","판별자를 먼저 학습 -> 어느 정도 학습된 판별자를 이용하여 생성자 학습\r\n","\r\n","+) 판별자가 중요한 역할이기 때문에 판별자의 학습 속도를 높히기 위해, 1번 단계를 여러번 반복 후 2번 단계로 넘어가기도 한다.\r\n","\r\n","- 판별자, 생성자 훈련, 손실함수 내용 참고 : http://dl-ai.blogspot.com/2017/08/gan-adversarial-learning.html"]},{"cell_type":"markdown","metadata":{"id":"JopGpTDgvC7F"},"source":["# GAN 모델의 훈련의 어려움\r\n","- 생성자, 판별자의 손실이 장기간 안정된 모습을 보여주지 못하고 큰 폭으로 진동하기 시작할 수 있다.\r\n","- 일반적으로 배치마다 손실의 약한 진동 O, 하지만, 손실이 안정/점진적 증가/점진적 감소하는 형태를 보여야 한다.\r\n","- 하지만, 장기적으로 심하게 출렁이는 경우가 GAN 모델의 훈련에서는 많이 발생한다."]},{"cell_type":"markdown","metadata":{"id":"X5XM4Imsf1ga"},"source":["## 모드 붕괴(mode collapse)\r\n","- 생성자가 판별자를 속이는 적은 양의 샘플을 발견했을 때를 의미.\r\n","- 한정된 샘플 외에는 다른 샘플을 생성하지 못한다.\r\n","- 모드(mode) : 판별자를 항상 속이는 하나의 샘플\r\n","- 즉, 판별자의 가중치를 업데이트 하지 않고 생성자만 계속 훈련시키면 판별자를 항상 속이는 샘플. 모드를 조금 발견할 수 있다. -> 이렇게 되면 생성자는 그 외에 다른 패턴의 샘플을 만들 필요가 없으므로 계속 그 샘플 형태의 데이터만 만들어내게 된다. 이게 바로 모드 붕괴이다."]},{"cell_type":"markdown","metadata":{"id":"00H7QgKGglbT"},"source":["## 유용하지 않은 손실\r\n","- 생성자의 손실, 생성된 이미지의 품질 사이의 연관성 부족 -> GAN 훈련과정을 모니터링하기 어렵게 한다.\r\n","- 이유 ? 생성자는 현재의 판별자에 의해 평가된다. 판별자의 성능은 점차 훈련 과정을 거치면서 향상된다. 따라서, 훈련 과정의 다른 지점에서 평가된 손실을 비교할 수 없다.\r\n","- 즉, 현재의 생성자의 손실을 판단하는 것은 현재의 판별자에 의해서이다. 하지만, GAN 모델 전체의 훈련 과정이 진행됨에 따라 각 시점의 판별자의 성능이 점차 향상된다. 따라서 다른 시점과 현재 시점과의 손실을 비교할 수 없다."]},{"cell_type":"markdown","metadata":{"id":"0_BKqDvUv7Np"},"source":["## 하이퍼파라미터 조정의 어려움\r\n","- GAN 모델 안의 튜닝해야 할 하이퍼파라미터의 갯수가 엄청 많다.\r\n","- 판별자, 생성자의 구조, 배치 정규화, 드롭아웃 학습률, 호라성화 층, 합성곱 필터, 커널 크기, 스트라이드, 배치 크기, 잠재 공간 크기 결정하는 하이퍼파라미터 고려 필요.\r\n","- GAN 모델은 이러한 하이퍼파라미터의 작은 변화에도 아주 민감하게 반응한다. 미리 정해져있는 가이드라인이 따로 있는 것이 아닌, 계획적인 시행착오를 거쳐서 잘 맞는 파라미터 조합을 찾는 경우가 많다."]},{"cell_type":"markdown","metadata":{"id":"o0hdrlw7yYgO"},"source":["이러한 GAN 모델의 문제점의 발생 가능성을 줄인 모델\r\n","- WGAN (Wasserstein GAN)\r\n","  - 손실함수를 binary cross entropy에서 Wasserstein 손실 함수를 대신 사용\r\n","- WGAN-GP (Wasserstein GAN-Gradient Penalty)\r\n","  - 오늘날 매우 복잡한 GAN을 훈련하는 데 최선의 방법으로 간주된다."]},{"cell_type":"code","metadata":{"id":"DfY0kMM84BZy"},"source":[""],"execution_count":null,"outputs":[]}]}