{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"모르는 개념 검색하여 정리.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNNWM2D3sHDDvKE8l0nYomM"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2y3a3nqeXug0"},"source":["# lookup table(순람표, 룩업 테이블)\r\n","- 컴퓨터 과학에서 일반적으로 배열이나 연관 배열로 된 데이터 구조\r\n","- 간단한 배열 인덱싱 동작으로 검색"]},{"cell_type":"markdown","metadata":{"id":"393Qm3HTYF1R"},"source":["# Word Embedding\r\n","- $W(\\text{\"cat\"}) = (0,2, -0,4, 0.7, \\cdots) \\\\ W(\\text{\"mat\"}) = (0.0, 0.6, -0.1, \\cdots)$\r\n","- 단어를 고차원의 벡터로 보내주는 함수\r\n"]},{"cell_type":"markdown","metadata":{"id":"x6Z7hCcoYutL"},"source":["# Representation Learning(표현 학습)\r\n","- Representation ? 모델의 각 층(multi-scaled)에서 나오는 feature map들의 집합을 의미.\r\n","- 데이터의 복잡한 구조를 multiple level로 바꿔주는 것\r\n","- 최적의 특징을 자동으로 알아낸다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"tMBFDrIeaiRz"},"source":["# Curse of dimensionality(차원의 저주)\r\n","- 데이터의 차원 증가 -> 해당 공간의 크기(부피) 기하급수적으로 증가 -> 동일한 갯수의 데이터의 밀도 급속도로 감소\r\n","- 따라서 차원이 증가할수록 데이터의 분포 분석, 모델 추정에 필요한 샘플 데이터의 갯수가 기하급수적으로 증가"]},{"cell_type":"markdown","metadata":{"id":"uZpQN4W4uyCA"},"source":["# Transfer Learning(전이 학습)\r\n","- 특정 환경에서 만들어진 AI 알고리즘을 다른 **비슷한 분야**에 적용하는 것\r\n","- ex) 체스 AI 에게 장기를 두게 한다. 사과깎는 AI에게 배를 깎게 한다."]},{"cell_type":"markdown","metadata":{"id":"ZkECIMYH7rLK"},"source":["# Downsampling\r\n","- 차원을 줄여서 적은 메모리로 깊은 convolution을 할 수 있게 하는 것\r\n","- 보통 stride를 2 이상으로 하는 convolution 층을 사용하거나 pooling 층을 사용 -> 이 과정에서 어쩔 수 없이 feature의 정보를 잃음\r\n","- Downsampling하는 부분을 Encoder라고 한다.\r\n","- 입력받은 이미지의 정보 -> 인코더 -> 압축된 벡터 출력"]},{"cell_type":"markdown","metadata":{"id":"OoTpcfKG8EDN"},"source":["# Upsampling\r\n","- Downsampling을 통해서 받은 결과의 차원을 늘려서 input과 같은 차원으로 만들어주는 과정\r\n","- 주로 strided transpose convolution을 사용\r\n","- Upsampling하는 부분을 Decoder라고 한다.\r\n","- 압축된 벡터 -> 디코더 -> 입력받은 이미지와 크기가 동일한 결과물 출력"]},{"cell_type":"markdown","metadata":{"id":"rbEOEqov8MTP"},"source":["# Covariate(공변량)\r\n","- 여러 변수들이 공통적으로 함께 공유하고 있는 변량. 종속변수에 대하여 독립변수와 기타 잡음인자들이 공유하는 변량.\r\n","- 연구를 진행하는 데 잡음인자가 있을 경우, 독립변수의 순수한 영향력을 검출해낼 수 없으므로 공변량을 이용하여 잡음인자를 통제.\r\n","- 공변량 분석의 목적 : 독립변수 이외의 잡음인자들이 조속변수에 영향을 미치는 것을 통제함으로써 독립변수 자체의 순수한 영향을 측정하는 것\r\n"]},{"cell_type":"markdown","metadata":{"id":"phvrMlvtDLTN"},"source":["# Internal Covariate Shift\r\n","- <img src=\"https://gaussian37.github.io/assets/img/dl/concept/batchnorm/3.png\" width=800>\r\n","- 딥러닝 네트워크에서 hidden layer를 거칠 때마다 각 층의 Activation에 영향을 받아 각 층마다의 input의 분포가 달라지는 현상\r\n","- Batch Normalization 층을 더하거나, hidden layer들에 대한 input을 정상화함으로써 문제 해결"]},{"cell_type":"markdown","metadata":{"id":"Wn9JAw0izpyB"},"source":["# Normalization(정규화)\r\n","- 신경망의 학습을 빠르게 할 수 있는 방법들 중 하나는 입력 데이터를 정규화하는 것.\r\n","- 입력 데이터를 정규화하지 않으면 손실 함수가 최저값으로 수렴하는 데 오랜 시간이 걸림. 또한, learning rate(학습률)을 크게 설정한다면 값이 발생할 위험이 있어 까다로움.\r\n","- 입력 데이터를 정규화해주게 된다면 -> 손실 함수의 수렴이 빠르게 이루어지고 안정적이게 된다.\r\n","- unnormalized는 앞뒤로 왔다갔다 하면서 수 많은 단계를 거쳐 최적값에 도달한다. 또한, learning  rate(학습률)을 작게 설정해야 한다.\r\n","- normalized는 어디서 시작하든 쉽게 최적값에 도달할 수 있다. learning rate(학습률)을 상대적으로 높혀서 사용할 수 있기 때문에 빠르게 훈련이 가능하다."]},{"cell_type":"markdown","metadata":{"id":"K9AipVUCDV4P"},"source":["# Batch Normalization(배치 정규화)\r\n","- 논문 버전\r\n","  - Internal Covariate Shift 현상을 막기 위한 방법\r\n","  - <img src=\"https://shuuki4.files.wordpress.com/2016/01/bn1.png\">\r\n","  - 학습 단계 : 각각의 배치 단위의 평균, 분산으로 정규화\r\n","    - 정해지지 X 값!\r\n","  - 추론 단계(테스트 단계) : 계산해놓은 이동 평균, 이동 분산 또는 지수 평균, 지수 분산으로 정규화\r\n","    - 정해진 값!\r\n","    - 이동 평균(moving average), 이동 분산(moving variance) -> 최근 N개의 배치의 데이터만 사용\r\n","    - 지수 평균, 지수 분산 -> 전체 데이터 사용\r\n","    - 주로, 이동 평균과 이동 분산을 사용한다.\r\n","  - 정규화한 이후에는 scale factor($\\gamma$), shift factor($\\beta$)를 이용하여 새로운 값 출력\r\n","  - $\\gamma, \\beta$ 파라미터\r\n","    - 학습 단계에서 backpropagation(역전파) 과정에서 학습되는 파라미터\r\n","    - 단순히 표준정규분포를 따르게 만드는 것이 아니라 우리가 원하는 분포를 따르도록 만들 수 있다. 또한, ReLU 활성화 함수를 거치게 되면 0보다 작은 것은 다 무시하는데 그 무시하는 부분을 줄일 수 있게 이동시킬 수도 있다.\r\n","  - 배치 정규화는 하이퍼파라미터 탐색을 쉽게 만들어줄 뿐만 아니라, 신경망과 하이퍼파라미터의 상관관계를 줄여준다.\r\n","- 유투브 본 설명 버전\r\n","  - 가중치 w,b를 빠르게 학습하기 위해서 layer의 출력값인 a를 정규화하는 것이 효과적이다. \r\n","  - 하지만, 활성화 함수를 거친 후인 a를 정규화하는 것보다 활성화 함수를 거치기 전인 z를 정규화하는 것이 더 많이 사용되고 있다. \r\n","  - 그렇다면 어떻게 배치 정규화를 구현하는가? \r\n","  - 위의 그림처럼 z의 평균, 분산을 구한다. 그 후, 정규화된 z($z_{norm}$을 구하게 되는 데 $z_{norm}$은 항상 평균이 0, 분산이 1인 분포를 따른다. \r\n","  - 하지만! 신경망의 은닉층의 분포가 전부 비슷해지게 되면 은닉층을 깊게 쌓는 의미가 없어지기 때문에 은닉층의 분포가 다양해야 한다. \r\n","  - 그래서 만들어진 방법이 배치 정규화. 그래서 $z_{norm}$ 대신해서 $\\hat{z} = \\gamma*z_{norm}+\\beta$를 사용한다.\r\n","  - 그렇게 되면 경사적 하강법, momentum, RMSprop, Adam을 이용한 경사하강법 등의 알고리즘을 사용하여 $\\gamma, \\beta$를 업데이트(학습)시킨다. -> $\\gamma, \\beta$의 값에 따라 $\\hat{z}$의 평균, 분산을 마음대로 설정 가능하게 된다.\r\n","  - 즉, $\\gamma, \\beta$의 값을 변화시키면서 은닉층의 값($z_{i}$)들이 서로 다른 평균, 분산의 분포를 따르도록 할 수 있다는 것이다! 이게 바로 배치 정규화의 핵심!\r\n","  - 즉, 요약하자면 은닉 유닛이 표준화된 평균, 분산을 갖되 평균, 분산은 학습 알고리즘에서 설정할 수 있는 두 변수 $\\gamma, \\beta$에 의해 조절된다.\r\n","  - 은닉층의 입력값의 분포를 내가 원하는 대로 바꿔줄 수 있다!\r\n","  - 참고 : https://www.youtube.com/watch?v=tNIpEZLv_eg\r\n","- 가장 간단한 설명 버전\r\n","  - <img src=\"https://gaussian37.github.io/assets/img/dl/concept/batchnorm/4.png\" width=800>\r\n","  - 이렇게 같은 층이더라도 배치 단위에 따라서 분포가 다른 것을 같은 층 내에서는 분포가 모두 같아지게! 각각의 원래 배치 단위의 평균, 분산을 이용해서 정규화하는 것을 배치 정규화!\r\n","  - 참고 : https://gaussian37.github.io/dl-concept-batchnorm/\r\n","\r\n","- 궁금증\r\n","  1. 왜 activation 층 이전에 배치 정규화 층을 두는가?\r\n","  - 이유 : 배치 정규화의 목적 자체가 네트워크의 각 층의 연산 결과가 우리가 원하는 방향의 분포대로 나오게 하는 것. variance가 크게 되어 gradient exploding, gradient vanishing 과 같은 문제가 생기지 않게 variance를 조절해주는 것.\r\n","  - 그래서 activation 층에 들어가기 전의 분포가 많이 바뀌지 않도록 activation 층 이전에 사용한다.\r\n","  - 주로, convolution layer나 fully-connected layer와 같이 핵심 연산을 한 후 분포가 많이 변화되어있으니까 그 직후에 batch normalization 층을 사용한다.\r\n","  2. 그렇다면 배치 정규화 층이 우리가 원하는 분포를 따르도록 바꿔줄 수 있으니까 아무 분포나 설정해도 되는가?\r\n","  - 이유 : 아니다. 주로 표준정규분포를 따르도록 (평균:0, 분산:1) 한다. 그 이유는 활성화 함수 ReLU, Sigmoid 등의 함수를 보면\r\n","  - <img src=\"https://miro.medium.com/max/666/1*nrxtwp6rzqdFhgYh0x-eVw.png\" width=800>\r\n","  - 주로 0 근처의 값에서 의미있다.\r\n","  - 또한, 배치 정규화 층의 목적 자체가 variance가 너무 크지 않게(크게 되면 네트워크의 층을 지날수록 점점 차이가 더 벌어지므로) 조절하는 것이므로 작은 variance를 사용하는 것이 좋다. 단, 너무 작은 variance를 사용하게 되면 분포가 0에 가깝게 수렴하게 되므로 너무 작은 variance가 아닌, 경험적으로 적절한 variance인 1을 사용하는 것이다.\r\n","\r\n","- batch normalization 의 장점\r\n"," - Internal Covariate Shift 문제를 개선하고자 하는 방법에는 Weight Initialization 방법을 사용하는 것, learning rate를 작게 조절하는 것 등이 있는 데 이러한 방법들에는 또 다른 문제가 발생하기 때문에\r\n"," - batch normalization을 사용함으로써 그러한 또 다른 문제를 발생시키지 않고 Internal Covariate Shift 문제를 개선할 수 있다.\r\n"," - 또한, overfitting 문제를 방지할 수 있는 regularization(정규화) 효과도 있다.\r\n","  "]},{"cell_type":"markdown","metadata":{"id":"Q8v3AQt7z6J6"},"source":["# 정규화 VS 배치 정규화\r\n","- 정규화 : 신경망의 입력값을 정규화\r\n","- 배치 정규화 : 신경망 안의 은닉층을 정규화\r\n","  - 은닉층의 입력값인 $z_{i}$의 분포(평균, 분산)을 정규화\r\n","  - 은닉층의 입력값. 즉 feature의 scale을 맞춰준다.\r\n","    - 그로 인한 효과? feature의 scale이 다 다르다면 -> gradient descent에 따른 weight의 영향이 각자 다르기 때문에\r\n","    - gradient의 편차가 클 때는 gradient exploding의 문제가 발생할 수 있고\r\n","    - gradient의 편차가 작을 때는 gradient vanishing의 문제가 발생할 수 있다.\r\n","  - 따라서, 정규화를 통해 gradient descent에 따른 weight의 반응을 다 맞춰줄 수 있다."]},{"cell_type":"markdown","metadata":{"id":"n1G_oQ8bt6pz"},"source":["# Gradient Descent(경사 하강법) VS Stochastic Gradient Descent(SGD, 확률적 경사 하강법)\r\n","- 전체 데이터로 한 번에 학습할 때 -> 경사 하강법 사용\r\n","  - 경사 하강법 : 데이터셋의 모든 데이터를 다 사용하여 학습.\r\n","  - 모든 gradient를 구하고 그 모든 gradient를 평균낸 다음에 업데이트\r\n","- 미니배치 단위로 학습할 때 -> 확률적 경사 하강법 사용\r\n","  - 확률적 경사 하강법 : 미니배치 단위로 배치마다 학습.\r\n","  - 그 뭉치마다의 gradient를 구하고 그 gradient들을 평균낸 다음에 업데이트"]},{"cell_type":"markdown","metadata":{"id":"5j753Oh1LkzI"},"source":["# Pre-training VS Fine-tuning\r\n","- Pre-training : 선행학습, 사전훈련, 전처리과정\r\n","  - 다중 레이어 퍼셉트론(MLP, Multi Layered Perceptron)에서 가중치, 편향을 잘 초기화시키는 방법\r\n","- Fine-tuning\r\n","  - 기존에 학습되어있는 모델을 기반으로 architecture를 나의 이미지 데이터에 맞는 **새로운 목적**에 맞게 **변형**하고 이미 학습된 모델의 가중치로부터 학습을 업데이트 하는 방법\r\n","  - **정교한 파라미터** 튜닝 방법\r\n","  - 이미 학습된 모델을 사용하는 것만으로는 fine-tuning 방법을 사용했다고 말할 수 없다. 이미 학습된 모델에 내 데이터를 추가로 학습시켜서 파라미터를 업데이트 했을 때 fine-tuning한 것이다.\r\n","  - 주의할 점 : 완전 랜덤한 초기 파라미터를 쓴다거나 가장 초기의 레이어의 파라미터를 학습해버리면 overfitting이 일어나거나 전체 파라미터가 망가지는 문제가 발생할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"jGwPStZQcDux"},"source":["---\r\n","---\r\n","# CartoonGAN 논문 추가 개념 설명\r\n","## 비사실적 렌더링(Non-photorealistic rendering)\r\n","- 컴퓨터 그래픽스의 한 영역. 사실적인 렌더링 이외의 표현. \r\n","- 양식. 회화, 드로잉, 만화 같이 렌더링하는 것.\r\n","\r\n","## 희소 표현(sparse representation)\r\n","- 대부분 0으로 표현되는 것. 종종 차원의 크기가 크다.\r\n","\r\n","## 특성 교차\r\n","- 특성들을 조합하여 새로운 특성을 만들어내는 것\r\n","- 원래보다 차원의 크기가 커진다.\r\n","- 원래보다 자원을 더 많이 필요로 한다.\r\n","\r\n","## 자원을 많이 차지할 때\r\n","- 가중치가 정확하게 0으로 떨어지도록 유도하는 것이 좋다.\r\n","- 가중치가 정확하게 0이 될 경우 모델에서 해당 특성을 삭제하게 되므로, 자원 소모량이 줄어들게 된다.\r\n","\r\n","## 희소성을 위한 정규화 : $l_{1}, l_{2}$ 규제(정규화)\r\n","- 규제 : 가중치의 성장을 제한한다. 일반적인 패턴이 아닌 몇몇 독특하면서 희소한 패턴을 가지는 데이터(noise, outlier)로부터 영향을 적게 받겠다.\r\n","- $l_{1}$ \r\n","  - 가중치의 절댓값에 패널티를 준다.\r\n","  - 관련성이 없거나 매우 낮은 특성의 가중치를 정확히 0으로 유도. 모델에서 해당 특성을 배제하는 데 도움이 된다.\r\n","- $l_{2}$\r\n","  - 가중치의 제곱값에 패널티를 준다.\r\n","  - 가중치를 0에 가깝게 유도하는 데 도움을 준다.\r\n","  - 선형 모델의 일반화를 항상 개선한다.\r\n","- 참고 : https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization?hl=ko\r\n","\r\n","## 매니폴드(manifold)\r\n","- 매니폴드란 고차원 데이터가 있을 때, 고차원 데이터를 데이터 공간에 뿌리면 sample들을 잘 아우르는 subspace가 있을 것이라는 가정하에서 학습을 진행하는 방법.\r\n","- manifold는 고차원 데이터를 잘 표현한다. 즉, 데이터의 중요한 특징을 잘 발견한다는 뜻.\r\n","- 샘플이 집중적으로 놓인 원래 특징 공간보다 낮은 차원의 공간을 의미.\r\n","- 두 점의 거리 or 유사도를 보았을 때\r\n","- 근거리에서는 유클리디안(직선 거리)를 따른다.\r\n","- 원거리에서는 유클리디안을 따르지 않는다.\r\n","- 조그만 유클리디안 공간 조각들이 다닥다닥 붙어 이루어져서 전체적으로 보면 비유클리디안이 되는 공간을 의미한다.\r\n","- <img src=\"https://t1.daumcdn.net/tistoryfile/fs4/10_6_6_30_blog106301_attach_0_3.jpg?original\" width=250>\r\n","- 참고 : https://markov.tistory.com/39\r\n","\r\n","## 매니폴드 학습(manifold learning)\r\n","- 데이터(샘플)을 잘 아우르는 manifold를 찾게 되었다. -> 데이터에 핵심적인 feature를 잘 찾았다. -> manifold의 좌표를 조금씩 변경해가면서 데이터를 유의미하게 조금씩 변화시킬 수 있다.\r\n","\r\n","## 셀 셰이딩(cel shading)\r\n","- 비사실적으로 묘사하는 그래픽 기법 중 하나로 손으로 그린 듯한 효과를 준다.\r\n","- 만화를 모방하기 위해 자주 사용하는 기법이다.\r\n","\r\n","## Classification VS Localization(Detection) VS Segmentation\r\n","- Classification(분류) : input에 대해 하나의 label을 예측\r\n","- Localization/Detection(발견) : label을 예측 + 어디에 위치하는 지 정보를 제공. 물체가 있는 곳에 네모를 그리는 등\r\n","- Segmentation(분할) : 모든 픽셀의 label을 예측. 물체의 모양대로 테두리 선을 그림.\r\n","- <img src=\"https://miro.medium.com/max/700/1*cJ3oLJ2s8W_sCPmTuMgIlw.png\">\r\n","- 참고 : https://medium.com/hyunjulie/1%ED%8E%B8-semantic-segmentation-%EC%B2%AB%EA%B1%B8%EC%9D%8C-4180367ec9cb\r\n","\r\n","## Semantic Image Segmentation\r\n","- 목적 : 이미지에 있는 모든 픽셀을 해당되는 class로 분류하는 것.\r\n","- 이미지에 있는 모든 픽셀에 대한 예측을 하는 것이기 때문에 dense prediction이라고도 불린다.\r\n","- Semantic Image Segmentation은 같은 class의 instance를 구별하지 않는다. 즉, 사람 2명과 강아지 1마리가 있을 때 사람1, 사람2, 강아지라고 다른 사람이라고 구분하는 것이 아니라 사람, 사람, 강아지 라고 구분한다.\r\n","\r\n","## Gram Matrix\r\n","- style transfer를 이해하기 위해서는 Gram Matrix에 대한 이해가 필요.\r\n","- style transfer는 Gram Matrix의 차이를 줄이는 방향으로 학습한다.\r\n","- texture들간의 rgb 공분산을 구하는 것.\r\n","- style transfer에서 content(사진)과 style(스타일)을 섞을 때 사용됨\r\n","- Gram Matrix의 역할 : 네트워크의 각 층의 style representation들을 서로 내적하여 구한다. -> 각각의 층의 Gram Matrix의 loss를 줄이는 방향으로 학습 -> content, style의 loss가 어느 지점에서 합의를 보게 될 것인지를 구해줌.\r\n","- 참고 : https://kyounju.tistory.com/3\r\n","- 참고 : picture 폴더 내의 필기 3개 캡쳐 이미지\r\n","\r\n","## CNN의 feature map\r\n","- <img src=\"https://taewanmerepo.github.io/2018/01/cnn/conv.png\" width=600>\r\n","- convolution 층의 필터를 통과하여 얻어낸 결과\r\n","- activation map이라고도 한다.\r\n","\r\n","## Vanishing Gradient Problem(기울기값이 사라지는 문제)\r\n","- 역전파 과정 중에 gradient 항이 사라지는 문제이다.\r\n","- gradient값이 0이나 0에 가까워져서 학습이 불가능해지는 현상.\r\n","- 원인 : 활성화 함수로 **sigmoid 함수**를 사용할 때 발생.\r\n","  - sigmoid 함수의 도함수값을 구해보면 최댓값이 0.25이다. 즉, 신경망의 깊이가 깊어질수록 gradient가 0.25씩 줄어든다는 의미이다. \r\n","- 해결 방법 : 활성화함수를 바꿔준다.\r\n","  - tanh 함수의 도함수값의 최댓값 : 1 -> 기울기값이 사라지는 문제가 조금 완화된다.\r\n","  - ReLU 함수의 도함수값 : 0 또는 1 -> 컴퓨팅 자원 소모량을 줄일 수 있다.\r\n","    - 하지만, ReLU 함수는 입력값이 0보다 작을 경우 -> 0을 출력 -> 0을 반환한 노드의 경우 다시 값을 갖기 어려움 -> 노드가 죽어버림\r\n","    - 그래서 ReLU 함수를 개선한 Leaky ReLU, PReLU 등의 함수를 사용하기도 한다.\r\n","    - 하지만, 기본적으로는 활성화함수로 **tanh, ReLU 함수**를 많이 사용한다.\r\n","\r\n","## Residual Block\r\n","- <img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbFPOry%2FbtqzR2En9ry%2F2DTETgT1BkCrW74hKQCsrk%2Fimg.png\" width=400>\r\n","- ResNet의 핵심 아이디어이다.\r\n","- 기존 방식과의 차이가 있는 데, gradient가 잘 흐를 수 있도록 일종의 지름길(shortcut, skip connection)을 만들어주는 것이다.\r\n","- LSTM에서도 forget gate등 다양한 gate의 개념을 도입시켜서 이전 step의 정보(gradient)들을 좀 더 잘 흐르게 만들려는 목적이었는 데 그와 비슷한 느낌이라고 보면 된다.\r\n","- 참고 : https://bskyvision.com/644\r\n","- 참고 : https://ratsgo.github.io/deep%20learning/2017/10/09/CNNs/\r\n","\r\n","## Downstream Task(다운스트림 태스크)\r\n","- 구체적으로 풀고 싶은 문제\r\n","- 파인 튜닝 방식을 통해 모델을 업데이트 하는 방식을 사용할 때 원하고자 하는 task를 downstream task라고 한다.\r\n","  - 파인 튜닝 방식 : 기존에 학습된 모델에 나의 새로운 데이터를 학습시켜서 기존 학습 모델의 파라미터를 업데이트 하여 사용하는 방식\r\n","\r\n","## Invariant local features\r\n","- 이미지 간의 feature를 매칭시키기 위해 필요한 불변의 특징\r\n","- geometric invariance : translation, rotation, scale, perspective projection,...\r\n","- photometric invariance : brightness, exposure, contrast,...\r\n","\r\n","## Image Feature\r\n","- 이미지를 수치적인 관점에서 추출한 정보\r\n","- 인간이 상호관계를 이해하기 어렵다.\r\n","- 이미지의 feature를 추출하는 이유 : 원본 이미지보다 차원이 낮아서 많은 이미지를 처리하는 overhead를 낮출 수 있다.\r\n","- 평균 밝기, 히스토그램, 엣지, 직선 성분, 코너 등등\r\n","- Feature Point(특징점, 키포인트, 관심점(interest point)) : 코너처럼 한 점의 형태로 표현할 수 있는 특징\r\n","- 엣지(edge) : 이미지의 강도(intensity)가 급격하게 변하는 부분\r\n","- 코너(corner) : 엣지의 방향이 급격하게 변하는 부분. 삼각형의 꼭지점이나 연필 심처럼 뾰족하게 튀어나와있는 부분. 엣지나 직선 성분에 비해 변별력이 높고 대체로 영상 전 영역에 골고루 분포하기 때문에 영상을 분석하는 데 중요한 Local feature로 사용된다.\r\n","    - <img src=\"https://drive.google.com/uc?id=1uK4QlqE2_rQMkePXov4oTOMZSmYvqg2v\" width=300>\r\n","    - A : 평탄한 영역 ; 하늘 전체가 A와 비슷한 픽셀값 분포를 가져서 위치를 찾기 힘들다.\r\n","    - B : 엣지 ; 정확한 x좌표를 가늠하기 힘들다.\r\n","    - C : 코너 ; 건물과 산의 뾰족 튀어나온 부분으로 유일한 위치를 찾을 수 있다.\r\n","    - 이처럼 평탄한 영역, 엣지, 직선 성분에 비해 코너가 지역 특징으로 많이 사용된다. 위치를 찾는 데 도움이 된다.\r\n","\r\n","\r\n","## Global feature VS Local feature\r\n","- Global feature와 Local feature는 반대 개념이다.\r\n","1. Global feature\r\n","  - 이미지 검색, 객체 감지, 분류, 영상에서 어떤 물체가 존재하는지 찾는다.\r\n","  - 저수준 응용 프로그램에 사용\r\n","  - 윤곽표현, 모양 설명, 질감\r\n","\r\n","2. Local feature(지역 특징)\r\n","  - 일부 영역에서 추출할 수 있는 특징\r\n","  - 객체 인식, 식별에 사용\r\n","  - 고급 응용 프로그램에 사용\r\n","  - ex) 엣지, 직선, 성분, 코너 등등\r\n","- Global & Local feature fusion -> 컴퓨터의 overhead의 부작용과 인식의 정확성을 향상시킬 수 있다.\r\n","\r\n","## Filtering\r\n","- 픽셀 값에 임의의 함수를 적용하여 이미지를 향상시키는 것\r\n","\r\n","\r\n","## Gaussian Smoothing Filtering\r\n","- 가우시안 분포(=정규분포)를 영상처리에 적용한 것\r\n","- 목적 : 영상 내 잡음 제거\r\n","- 잡음 -> 가우시안 분포를 따른다. -> 가우시안 스무딩 필터를 사용하여 잡음 제거\r\n","- 랜덤하게 분포된 영상의 잡음을 분석해보면 가우시안 분포를 보인다.\r\n","- 엣지 검출에 활용\r\n","- 이미지를 흐리게 하거나 노이즈를 줄이는 데 사용된다.\r\n","- <img src=\"https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/gausmask.gif\" width=300>\r\n","- 위의 필터 그림처럼 중심 픽셀이 가장 큰 가중치를 갖고, 인접 픽셀의 가중치는 감소한다. -> 가우시안 분포가 중심(평균)을 중심으로 분포되어있기 때문이다. -> 이미지/영상의 엣지를 부드럽게 바꿔준다.\r\n","- Gaussian Smoothing Filter는 가우시안 분포 함수를 근사하여 생성한 필터 마스크를 사용하는 필터링 기법이다.\r\n","\r\n","\r\n","## Canny Edge Detection\r\n","- 가장 인기있는 엣지 검출 알고리즘 중 하나\r\n","- 윤곽을 가장 잘 찾아내면서도 원래 영상의 회색물질과 관련된 모든 엣지들을 제거할 수 있는 유일한 방법\r\n","- 단계\r\n","  - 1. 노이즈 제거(Noise Reduction)\r\n","    - 엣지 검출은 노이즈의 영향을 많이 받기 때문에 노이즈 제거를 제일 먼저 한다.\r\n","    - 5x5 Gaussian Filter를 이용하여 이미지의 노이즈를 줄여준다.\r\n","    - 이미지의 상세한 부분이 단순화되고, 이미지의 노이즈도 같이 제거된다.\r\n","  - 2. edge gradient크기, 방향 계산\r\n","    - sobel kernel을 이미지에 convolution해서 수평, 수직 방향에 대한 1차 미분 이미지를 얻는다.\r\n","      - 수평 방향 1차 미분 이미지 : 수직선 검출\r\n","      - 수직 방향 1차 미분 이미지 : 수평선 검출\r\n","    - sobel 연산으로부터 구한 2개의 이미지 -> edge_gradient, angle(엣지 방향)을 구한다.\r\n","    - 엣지 방향은 실제 방향과 수직이다.\r\n","    - sobel 연산 결과 엣지가 검출된다.\r\n","  - 3. 최대값이 아닌 픽셀의 값을 0으로 만들기(non-maximum suppression)\r\n","    - 엣지가 될 수 없는 픽셀들을 제거한다.\r\n","    - 높은 픽셀과 낮은 픽셀 방향 사이에 엣지가 존재한다.\r\n","    - sobel 연산으로부터 구한 엣지가 얇아진다.(원래 두껍게 엣지를 구한것을 얇게 바꿔준다.)\r\n","  - 4. Hyteresis Thresholding\r\n","    - 2개의 threshold 값을 사용하여 이전 단계에서 얻어진 것들 중 진짜 엣지로 보이는 것만 놔두고 나머지는 제거한다.\r\n","    - 모든 가장자리가 실제 가장자리인지/아닌지를 결정\r\n","    - 2개의 임계값 : minVal, maxVal\r\n","    - 가장자리 < minVal -> 가장자리가 아님. 버린다.\r\n","    - maxVal < 가장자리 -> 확실한 가장자리이다!\r\n","    - minVal < 가장자리 < maxVal -> 가장자리 또는 비 가장자리로 분류된다. 픽셀이 확실한 픽셀에 연결되면 가장자리의 일부로 간주. 그렇지 않으면 버려진다.\r\n","    - <img src=\"https://opencv-python-tutroals.readthedocs.io/en/latest/_images/hysteresis.jpg\" width=500>\r\n","    - 엣지 A : maxVal 보다 크므로 -> 확실한 가장자리!\r\n","    - 엣지 C : minVal ~ maxVal 사이에 존재 -> A에 연결되므로 유효한 엣지로 간주!\r\n","    - 엣지 B : 엣지 C와 동일하게 minVal ~ maxVal 사이에 존재하지만 어떠한 확실한 가장자리에도 연결되어있지 X -> 삭제됨!\r\n","    - -> 올바른 결과를 얻으려면 minVal, maxVal 값의 선택이 중요!\r\n","- 참고 : https://webnautes.tistory.com/687\r\n","- 참고 : https://docs.opencv.org/master/da/d22/tutorial_py_canny.html\r\n","\r\n","## Ablation study(제거 실험), Ablation experiment\r\n","- 모델이나 알고리즘을 구성하는 다양한 구성요소(component)들 중에서 어떠한 feature를 제거했을 때 성능(performance)에 어떠한 영향을 미치는지를 파악하는 방법\r\n","\r\n","\r\n","## Key frame\r\n","- 동영상 응용에서 사용하는 언어\r\n","- frame : 비디오 애니메이션의 최소 단위. 영화 필름의 각 장면.\r\n","- key frame : 매개 변수에 대한 변경의 시작 또는 끝을 나타내는 데 사용되는 프레임. 효과를 줄 때 기준이 되는 처음과 끝.\r\n","- key frame과 다른 key frame 사이에 애니메이션을 만들 수 있다.\r\n","- <img src=\"https://www.videosolo.com/images/editfun/frame.jpg\" width=600>\r\n","- 예를 들어 이렇게 사각형에서 원이 되는 이미지가 있다면 처음 1번 컷과 마지막 7번 컷이 key frame이 된다.\r\n","\r\n","## Style Transfer\r\n","- 영상 2개(content image, style image)가 주어졌을 때, 이미지의 주된 형태 : content image와 유사 / style : style image와 유사하게 바꾸는 것을 말한다.\r\n","- Neural network를 이용한 Style Transfer의 연구는 2개의 분류로 나눌 수 있다.\r\n","  1. 미리 학습된 네트워크를 이용한 방법\r\n","    - ex) Image-net 등의 미리 학습된 네트워크\r\n","    - content image, style image를 네트워크에 통과시킬 때 나온 각각의 feature map을 저장\r\n","    - 새롭게 합성될 영상의 feature map이 content image, style image로부터 나온 feature map과 비슷한 특성을 가지도록 영상을 최적화한다.\r\n","    - 장점 : 이미지 단 2장(content image, style image)로 style transfer가 가능\r\n","    - 단점 : 매번 이미지를 새롭게 최적화 -> 시간이 오래 걸림\r\n","  2. Style transfer network를 학습시키는 방법\r\n","    - 서로 다른 두 domain(ex, 풍경 사진, 모네 그림)의 영상들이 주어졌을 때\r\n","    - 한 도메인에서 다른 도메인으로 바꿔주도록 학습\r\n","    - 장점 : 네트워크 한번 학습시킨 후에, 새로운 이미지에 적용할 때, feed forward만 해주면 된다.\r\n","    - 단점 : 새로운 네트워크 학습해줘야 하므로, 각 도메인마다 여러 개의 영상이 필요. 학습에 시간이 소요된다.\r\n","\r\n","- 참고 : https://blog.lunit.io/2017/04/27/style-transfer/\r\n"]},{"cell_type":"code","metadata":{"id":"18uyooj0stZF"},"source":[""],"execution_count":null,"outputs":[]}]}