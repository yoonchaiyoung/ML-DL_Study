{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG 논문 공부.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOavjyI79QKGK9chcUn9LS+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xaWqiOHxKl0D"},"source":["# Very Deep Convolutional Networks For Large-Scale Image Recognition"]},{"cell_type":"markdown","metadata":{"id":"USu6r_wIWsIB"},"source":["# Abstract(논문 개요)\r\n","- 이 연구에서는 우리는 대규모 이미지 인식 설정에서의 정확도에 대한 컨볼루젼 신경망의 깊이의 영향을 조사한다.\r\n","- 매우 작은 (3x3) 컨볼루젼 필터의 구조의 깊이를 증가시킨 신경망에 대해 철저히 평가했다. 16 ~ 19 깊이의 가중치 layer로 인해 선행 기술 구성에서 상당한 개선을 달성하였다.\r\n","- 이러한 발견은 우리의 ImageNet Challenge 2014 결과의 기반이 되었다. 우리 팀은 각각 localisation과  classification 분야에서 각각 1등과 2등을 차지했다.\r\n","- 우리의 표현(representation)이 다른 데이터셋에서도 잘 일반화되는 것을 보여준다. 최신 기술의 결과를 달성한다.\r\n","- 우리는 computer vision의 깊은 시각적 표현의 사용에 대한 더 나은 연구를 가능하게 하기 위해서 최고의 성능을 내는 2개의 ConvNet 모델을 공개적으로 사용할 수 있게 만들었다."]},{"cell_type":"markdown","metadata":{"id":"CsOooSkkZtkc"},"source":["# 1. Introduction\r\n","- 컨볼루젼 네트워크(ConvNets)는 최근 대규모 이미지 및 비디오 인식에서 큰 성공을 거두었다. (Krizhevsky et al., 2012; Zeiler & Fergus, 2013; Sermanet et al., 2014; Simonyan & Zisserman, 2014) 이 대회들은 ImageNet (Deng et al., 2009)와 같은 대규모 공개 이미지 저장소, GPU 또는 대규모 분산 클러스터와 같은 고성능 컴퓨팅 시스템 (Dean et al., 2012)으로 인해 가능해졌다.\r\n","- 특히, 심층 시각 인식 아키텍처(deep visual recognition architectures)의 발전에서 중요한 역할은 ImageNet 대규모 시각 인식 챌린지 (ILSVRC) (Russakovsky et al., 2014)에 의해서이다. 이는 고차원의 이미지 분류 시스템의 수 세대에 걸쳐 시험대 역할을 해왔다. 고차원의 얕은 feature encoding (Perronnin et al., 2010) (the winner of ILSVRC-2011) 으로부터 Deep ConvNets (Krizhevsky et al., 2012) (the winner of ILSVRC-2012)까지.\r\n","- ConvNets가 computer vision 분야에서 상품이 되면서, Krizhevsky et al. (2012)의 원래의 아키텍쳐를 개선하기 위한 많은 시도들이 생겨났다. 더 나은 정확도를 달성하기 위해.\r\n","- 예를 들어, ILSVRC2013 (Zeiler & Fergus, 2013; Sermanet et al., 2014) 대회에서 가장 실력이 좋은 제출(submission)은 첫번째 컨볼루젼 층에 더 작은 window size와 더 작은 stride를 사용했다.\r\n","- 또 다른 개선점은 전체 이미지와 여러 스케일에 걸쳐서 네트워크를 세세하게 훈련하고 테스트하는 것이다.\r\n","- 이 논문에서는, 우리는 ConvNet의 또 다른 중요한 측면인 깊이(depth)를 다룬다.\r\n","- 이를 위해, 우리는 구조의 다른 파라미터들을 고정시키고 더 많은 컨볼루젼 층을 쌓음으로써 네트워크의 깊이를 끊임없이 증가시켰다. 이것은 매우 작은 (3x3) 컨볼루젼 필터를 모든 층에 사용하기 때문에 실현 가능한(feasible) 것이다.\r\n","- 그 결과, 우리는 상당히 더 정확한 ConvNet 구조를 찾아냈다. ILSVRC 분류 및 localisation 작업에 대해 최신의 정확도를 달성할 뿐만 아니라, 다른 이미지 인식 데이터셋에도 사용가능하다. 그리고 상대적으로 간단한 파이프라인의 한 부분으로써 사용할 때에도 우수한 성능을 달성한다. (예, fine-tuning없이 선형 SVM에 의해 deep feature 분류)\r\n","- 추가의 연구를 가능하게 하기 위해서 2개의 최적의 성능을 내는 모델을 공개하겠다.\r\n","- 나머지 논문은 다음과 같이 구성된다.\r\n","- Sect.2 : ConvNet의 구성\r\n","- Sect.3 : 이미지 분류를 훈련하는 과정의 세부 내용과 평가 내용\r\n","- Sect.4 : ILSVRC 분류 과제에서의 구성 과정과 비교\r\n","- Sect.5 : 논문의 결론 내용\r\n","- 부록 A : 우리의 ILSVRC-2014 객체 localisation 시스템을 설명, 평가\r\n","- 부록 B : 다른 데이터셋에 대한 very deep feature의 일반화에 대해 논의\r\n","- 부록 C : 주요 문서 검토 목록"]},{"cell_type":"code","metadata":{"id":"OAb3Zn4Ra1dO"},"source":[""],"execution_count":null,"outputs":[]}]}